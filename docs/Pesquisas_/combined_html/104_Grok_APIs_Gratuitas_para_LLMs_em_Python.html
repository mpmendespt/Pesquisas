<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang xml:lang>
<head>

        <style id="fixed-toc-styles">
        /* === ESTILOS PRINCIPAIS - TOC FIXO √Ä DIREITA === */
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
            color: #333;
            scroll-behavior: smooth;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            padding: 40px;
            border-radius: 10px;
            box-shadow: 0 5px 20px rgba(0,0,0,0.1);
            position: relative;
        }
        /* === TOC FIXO √Ä DIREITA - POSI√á√ÉO CORRIGIDA === */
        #TOC {
            position: fixed !important;
            top: 50% !important;
            right: 20px !important;
            transform: translateY(-50%) !important;
            width: 320px !important;
            max-height: 80vh !important;
            overflow-y: auto !important;
            z-index: 1000 !important;
            background: rgba(255, 255, 255, 0.98) !important;
            padding: 20px !important;
            border-radius: 12px !important;
            box-shadow: 0 8px 32px rgba(0,0,0,0.15) !important;
            border: 1px solid #e0e0e0 !important;
            backdrop-filter: blur(10px) !important;
            transition: all 0.3s ease-in-out !important;
        }
        #TOC.toc-minimized {
            transform: translateY(-50%) translateX(calc(320px - 50px)) !important;
            opacity: 0.3;
            width: 50px !important;
            overflow: hidden;
        }
        #TOC.toc-minimized > *:not(.toc-toggle-btn) {
            display: none !important;
        }
        #TOC h2 {
            margin-top: 0;
            color: #2c3e50;
            border-bottom: 2px solid #3498db;
            padding-bottom: 10px;
            font-size: 1.2em;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }
        .toc-toggle-btn {
            background: none;
            border: none;
            font-size: 1.2em;
            cursor: pointer;
            padding: 5px;
            border-radius: 4px;
            transition: background-color 0.2s;
        }
        .toc-toggle-btn:hover {
            background-color: rgba(0,0,0,0.1);
        }
        #TOC ul {
            list-style-type: none;
            padding-left: 15px;
            margin: 10px 0;
        }
        #TOC ul ul {
            padding-left: 20px;
        }
        #TOC li {
            margin: 8px 0;
            line-height: 1.4;
        }
        #TOC a {
            text-decoration: none;
            color: #495057;
            font-weight: 500;
            transition: all 0.2s ease;
            display: block;
            padding: 6px 10px;
            border-radius: 6px;
            border-left: 3px solid transparent;
        }
        #TOC a:hover {
            color: #007bff;
            background-color: rgba(0, 123, 255, 0.1);
            border-left-color: #007bff;
        }
        #TOC a.active {
            background-color: #007bff !important;
            color: white !important;
            font-weight: bold;
            border-left-color: #0056b3;
        }
        /* Conte√∫do principal com margem para o TOC */
        .main-content {
            margin-right: calc(320px + 40px) !important;
        }
        /* Barra de scroll personalizada APENAS para TOC */
        #TOC::-webkit-scrollbar {
            width: 8px;
        }
        #TOC::-webkit-scrollbar-track {
            background: #f1f1f1;
            border-radius: 4px;
        }
        #TOC::-webkit-scrollbar-thumb {
            background: #c1c1c1;
            border-radius: 4px;
        }
        #TOC::-webkit-scrollbar-thumb:hover {
            background: #a8a8a8;
        }
        /* === BOT√ÉO VOLTAR AO TOPO (HTMLs individuais) === */
        .back-to-top-content {
            position: fixed;
            bottom: 30px;
            right: 30px;
            background: #007bff;
            color: white;
            border: none;
            border-radius: 50%;
            width: 50px;
            height: 50px;
            font-size: 18px;
            cursor: pointer;
            box-shadow: 0 4px 12px rgba(0,0,0,0.15);
            opacity: 0;
            transition: all 0.3s ease;
            z-index: 999;
            display: flex;
            align-items: center;
            justify-content: center;
        }
        .back-to-top-content.show {
            opacity: 1;
            transform: translateY(0);
        }
        .back-to-top-content:hover {
            background: #0056b3;
            transform: translateY(-2px);
            box-shadow: 0 6px 16px rgba(0,0,0,0.2);
        }
        /* === RESPONSIVIDADE === */
        @media (max-width: 1400px) {
            .container {
                max-width: 95%;
                padding: 30px;
            }
            #TOC {
                width: 280px !important;
            }
            .main-content {
                margin-right: 320px !important;
            }
        }
        @media (max-width: 1200px) {
            #TOC {
                width: 260px !important;
                right: 15px !important;
            }
            .main-content {
                margin-right: 300px !important;
            }
        }
        @media (max-width: 992px) {
            #TOC {
                position: relative !important;
                width: 100% !important;
                right: 0 !important;
                top: 0 !important;
                transform: none !important;
                margin: 20px 0;
                max-height: 300px !important;
            }
            .main-content {
                margin-right: 0 !important;
            }
            .back-to-top-content {
                right: 20px;
                bottom: 20px;
            }
        }
        @media (max-width: 768px) {
            body {
                padding: 10px;
            }
            .container {
                padding: 20px;
                max-width: 100%;
            }
            #TOC {
                max-height: 250px !important;
                padding: 15px !important;
            }
        }
        </style>
        
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>104_Grok_APIs_Gratuitas_para_LLMs_em_Python</title>
  <style>

html {
color: #1a1a1a;
background-color: #fdfdfd;
}
body {
margin: 0 auto;
max-width: 36em;
padding-left: 50px;
padding-right: 50px;
padding-top: 50px;
padding-bottom: 50px;
hyphens: auto;
overflow-wrap: break-word;
text-rendering: optimizeLegibility;
font-kerning: normal;
}
@media (max-width: 600px) {
body {
font-size: 0.9em;
padding: 12px;
}
h1 {
font-size: 1.8em;
}
}
@media print {
html {
background-color: white;
}
body {
background-color: transparent;
color: black;
font-size: 12pt;
}
p, h2, h3 {
orphans: 3;
widows: 3;
}
h2, h3, h4 {
page-break-after: avoid;
}
}
p {
margin: 1em 0;
}
a {
color: #1a1a1a;
}
a:visited {
color: #1a1a1a;
}
img {
max-width: 100%;
}
svg {
height: auto;
max-width: 100%;
}
h1, h2, h3, h4, h5, h6 {
margin-top: 1.4em;
}
h5, h6 {
font-size: 1em;
font-style: italic;
}
h6 {
font-weight: normal;
}
ol, ul {
padding-left: 1.7em;
margin-top: 1em;
}
li > ol, li > ul {
margin-top: 0;
}
blockquote {
margin: 1em 0 1em 1.7em;
padding-left: 1em;
border-left: 2px solid #e6e6e6;
color: #606060;
}
code {
font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
font-size: 85%;
margin: 0;
hyphens: manual;
}
pre {
margin: 1em 0;
overflow: auto;
}
pre code {
padding: 0;
overflow: visible;
overflow-wrap: normal;
}
.sourceCode {
background-color: transparent;
overflow: visible;
}
hr {
border: none;
border-top: 1px solid #1a1a1a;
height: 1px;
margin: 1em 0;
}
table {
margin: 1em 0;
border-collapse: collapse;
width: 100%;
overflow-x: auto;
display: block;
font-variant-numeric: lining-nums tabular-nums;
}
table caption {
margin-bottom: 0.75em;
}
tbody {
margin-top: 0.5em;
border-top: 1px solid #1a1a1a;
border-bottom: 1px solid #1a1a1a;
}
th {
border-top: 1px solid #1a1a1a;
padding: 0.25em 0.5em 0.25em 0.5em;
}
td {
padding: 0.125em 0.5em 0.25em 0.5em;
}
header {
margin-bottom: 4em;
text-align: center;
}
#TOC li {
list-style: none;
}
#TOC ul {
padding-left: 1.3em;
}
#TOC > ul {
padding-left: 0;
}
#TOC a:not(:hover) {
text-decoration: none;
}
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}

ul.task-list[class]{list-style: none;}
ul.task-list li input[type="checkbox"] {
font-size: inherit;
width: 0.8em;
margin: 0 0.8em 0.2em -1.6em;
vertical-align: middle;
}

html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
</head>
<body>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#apis-gratuitas-para-llms-em-python" id="toc-apis-gratuitas-para-llms-em-python"><span class="toc-section-number">1</span> APIs Gratuitas para LLMs em
Python</a>
<ul>
<li><a href="#informa√ß√µes" id="toc-informa√ß√µes"><span class="toc-section-number">1.1</span> üìä Informa√ß√µes</a></li>
<li><a href="#conversa" id="toc-conversa"><span class="toc-section-number">1.2</span> üí¨ Conversa</a></li>
</ul></li>
</ul>
</nav>
<h1 data-number="1" id="apis-gratuitas-para-llms-em-python"><span class="header-section-number">1</span> APIs Gratuitas para LLMs em
Python</h1>
<h2 data-number="1.1" id="informa√ß√µes"><span class="header-section-number">1.1</span> üìä Informa√ß√µes</h2>
<ul>
<li><strong>N√∫mero:</strong> #104</li>
<li><strong>Origem:</strong> Grok</li>
<li><strong>Categoria:</strong> Programa√ß√£o</li>
<li><strong>ID:</strong> 92511678-a824-43ae-aead-b39a861012ad</li>
<li><strong>Criada em:</strong> 2025-10-22 14:26:26Z</li>
<li><strong>Atualizada em:</strong> 2025-10-22 14:26:45Z</li>
<li><strong>Total de mensagens:</strong> 2</li>
<li><strong>Resumo:</strong> Existe alguma alguma api gratuita de
chatgpt, deepseek, gork, ou semelhante que possa ser instalada ‚Ä¶</li>
</ul>
<hr />
<h2 data-number="1.2" id="conversa"><span class="header-section-number">1.2</span> üí¨ Conversa</h2>
<h3 data-number="1.2.1" id="utilizador-2025-10-22-152626-grok"><span class="header-section-number">1.2.1</span> üë§ Utilizador <em>(2025-10-22
15:26:26)</em> <em>[Grok]</em></h3>
<p>Existe alguma alguma api gratuita de chatgpt, deepseek, gork, ou
semelhante que possa ser instalada e integrada com python. Para produzir
uma aplica√ß√£o inteligente para pesquisa.</p>
<hr />
<h3 data-number="1.2.2" id="grok-2025-10-22-152643-grok"><span class="header-section-number">1.2.2</span> ü§ñ Grok <em>(2025-10-22
15:26:43)</em> <em>[Grok]</em></h3>
<p>Sim, existem v√°rias op√ß√µes de APIs gratuitas ou com tiers gratuitos
para modelos semelhantes ao ChatGPT, como DeepSeek, Grok (da xAI) e
outros LLMs open-source. Vou focar nas que podem ser integradas
facilmente com Python, ideais para uma aplica√ß√£o de pesquisa inteligente
(por exemplo, usando RAG - Retrieval-Augmented Generation, onde o LLM
processa consultas baseadas em dados pesquisados). Algumas s√£o APIs
hospedadas (com limites gratuitos), enquanto outras envolvem instala√ß√£o
local para uso ilimitado e privado.</p>
<p>Vou listar as principais op√ß√µes vi√°veis, com instru√ß√µes de instala√ß√£o
e integra√ß√£o em Python. Priorizei as gratuitas e open-source, evitando
custos recorrentes. Para pesquisa, recomendo modelos que suportem
racioc√≠nio avan√ßado (como DeepSeek ou Llama).</p>
<h3 data-number="1.2.3" id="deepseek-api-gratuita-com-limites-open-source"><span class="header-section-number">1.2.3</span> 1. <strong>DeepSeek API
(Gratuita com limites, open-source)</strong></h3>
<p>DeepSeek √© um modelo chin√™s poderoso para chat e racioc√≠nio, similar
ao GPT-4, com custo baixo (quase 2% do OpenAI em alguns casos). √â
gratuito via proxies como OpenRouter (tier free com limites di√°rios) ou
instala√ß√£o local. Perfeito para pesquisa por seu suporte a ‚Äúdeep
thinking‚Äù e busca integrada.</p>
<ul>
<li><strong>Via OpenRouter (hospedado, gratuito com limites)</strong>:
<ul>
<li><p>Crie conta gratuita em <a href="https://openrouter.ai">openrouter.ai</a> e pegue a API key (tier
free: ~1M tokens/m√™s).</p></li>
<li><p>Instale: <code>pip install openai requests</code></p></li>
<li><p>Exemplo de c√≥digo Python para chat/pesquisa:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> openai <span class="im">import</span> OpenAI</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>client <span class="op">=</span> OpenAI(</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    base_url<span class="op">=</span><span class="st">&quot;https://openrouter.ai/api/v1&quot;</span>,</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    api_key<span class="op">=</span>os.getenv(<span class="st">&quot;OPENROUTER_API_KEY&quot;</span>),  <span class="co"># Sua key</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> client.chat.completions.create(</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span><span class="st">&quot;deepseek/deepseek-chat:free&quot;</span>,  <span class="co"># Modelo free</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    messages<span class="op">=</span>[</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>        {<span class="st">&quot;role&quot;</span>: <span class="st">&quot;system&quot;</span>, <span class="st">&quot;content&quot;</span>: <span class="st">&quot;Voc√™ √© um assistente de pesquisa inteligente.&quot;</span>},</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>        {<span class="st">&quot;role&quot;</span>: <span class="st">&quot;user&quot;</span>, <span class="st">&quot;content&quot;</span>: <span class="st">&quot;Pesquise e resuma os impactos da IA na educa√ß√£o.&quot;</span>}</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    ],</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    max_tokens<span class="op">=</span><span class="dv">500</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(response.choices[<span class="dv">0</span>].message.content)</span></code></pre></div></li>
<li><p>Para app de pesquisa: Integre com bibliotecas como
<code>langchain</code> para adicionar busca web (ex: via SerpAPI free
tier).</p></li>
</ul></li>
<li><strong>Instala√ß√£o local (ilimitada, via Ollama)</strong>:
<ul>
<li><p>Instale Ollama:
<code>curl -fsSL https://ollama.com/install.sh | sh</code></p></li>
<li><p>Rode: <code>ollama pull deepseek-coder</code> (ou
similar).</p></li>
<li><p>Use com Python: <code>pip install ollama</code></p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> ollama</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> ollama.chat(model<span class="op">=</span><span class="st">&#39;deepseek-coder&#39;</span>, messages<span class="op">=</span>[</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    {<span class="st">&#39;role&#39;</span>: <span class="st">&#39;user&#39;</span>, <span class="st">&#39;content&#39;</span>: <span class="st">&#39;Resuma artigos sobre IA √©tica.&#39;</span>}</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(response[<span class="st">&#39;message&#39;</span>][<span class="st">&#39;content&#39;</span>])</span></code></pre></div></li>
<li><p>Vantagem: Roda no seu PC (GPU recomendada), sem limites.</p></li>
</ul></li>
</ul>
<h3 data-number="1.2.4" id="grok-api-da-xai-com-cr√©ditos-gratuitos"><span class="header-section-number">1.2.4</span> 2. <strong>Grok API (da xAI,
com cr√©ditos gratuitos)</strong></h3>
<p>Grok √© o modelo da xAI (de Elon Musk), focado em racioc√≠nio e busca
real-time. N√£o √© totalmente gratuito, mas oferece US$25 em cr√©ditos
mensais gr√°tis durante beta (at√© fim de 2024, prorrog√°vel). Compat√≠vel
com OpenAI SDK.</p>
<ul>
<li><p>Instale: <code>pip install xai-sdk</code> (ou use OpenAI
SDK).</p></li>
<li><p>Crie conta em <a href="https://console.x.ai">console.x.ai</a> e
pegue API key.</p></li>
<li><p>Exemplo Python:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> xai_sdk <span class="im">import</span> Client</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>client <span class="op">=</span> Client(api_key<span class="op">=</span>os.getenv(<span class="st">&quot;XAI_API_KEY&quot;</span>))</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> client.chat.completions.create(</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span><span class="st">&quot;grok-beta&quot;</span>,</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    messages<span class="op">=</span>[</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>        {<span class="st">&quot;role&quot;</span>: <span class="st">&quot;system&quot;</span>, <span class="st">&quot;content&quot;</span>: <span class="st">&quot;Assistente para pesquisa avan√ßada.&quot;</span>},</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>        {<span class="st">&quot;role&quot;</span>: <span class="st">&quot;user&quot;</span>, <span class="st">&quot;content&quot;</span>: <span class="st">&quot;Analise tend√™ncias em IA para 2025.&quot;</span>}</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(response.choices[<span class="dv">0</span>].message.content)</span></code></pre></div></li>
<li><p>Para pesquisa: Suporta tool calling nativo para integrar buscas
(ex: web search via API externa).</p></li>
<li><p>Limite: ~128k tokens de contexto, ideal para documentos
longos.</p></li>
</ul>
<p><strong>Nota</strong>: Para acesso 100% free, use via OpenRouter
(mesmo setup do DeepSeek, model=‚Äúxai/grok-3:free‚Äù).</p>
<h3 data-number="1.2.5" id="hugging-face-inference-api-gratuita-para-open-source-llms"><span class="header-section-number">1.2.5</span> 3. <strong>Hugging Face
Inference API (Gratuita para open-source LLMs)</strong></h3>
<p>Plataforma open-source com APIs gratuitas para modelos como Llama 3,
Mistral ou Phi-3. Limites: ~1k requests/dia free. √ìtimo para pesquisa,
com suporte a embeddings para busca sem√¢ntica.</p>
<ul>
<li><p>Crie conta em <a href="https://huggingface.co">huggingface.co</a>
e gere token em Settings &gt; Access Tokens.</p></li>
<li><p>Instale:
<code>pip install huggingface_hub requests</code></p></li>
<li><p>Exemplo para Llama 3 (similar a ChatGPT):</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>API_URL <span class="op">=</span> <span class="st">&quot;https://api-inference.huggingface.co/models/meta-llama/Llama-3-8B-Instruct&quot;</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>headers <span class="op">=</span> {<span class="st">&quot;Authorization&quot;</span>: <span class="ss">f&quot;Bearer SEU_TOKEN_AQUI&quot;</span>}</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> query(payload):</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    response <span class="op">=</span> requests.post(API_URL, headers<span class="op">=</span>headers, json<span class="op">=</span>payload)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> response.json()</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>output <span class="op">=</span> query({</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;inputs&quot;</span>: <span class="st">&quot;Voc√™ √© um pesquisador. Resuma os avan√ßos em LLMs open-source.&quot;</span>,</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;parameters&quot;</span>: {<span class="st">&quot;max_new_tokens&quot;</span>: <span class="dv">200</span>}</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(output)</span></code></pre></div></li>
<li><p>Para app de pesquisa: Use <code>sentence-transformers</code> para
embeddings e busque em vetores locais.</p></li>
</ul>
<h3 data-number="1.2.6" id="op√ß√µes-locais-open-source-instal√°veis-ilimitadas"><span class="header-section-number">1.2.6</span> 4. <strong>Op√ß√µes Locais
Open-Source (Instal√°veis, Ilimitadas)</strong></h3>
<p>Para privacidade total e sem custos, instale LLMs localmente com APIs
compat√≠veis. Roda em CPU/GPU.</p>
<ul>
<li><strong>Ollama (Recomendado para iniciantes)</strong>:
<ul>
<li>Instale como acima.</li>
<li>Modelos free: Llama 3, Mistral, Gemma.</li>
<li>Integra√ß√£o Python via <code>ollama</code> package (exemplo
acima).</li>
<li>Para pesquisa: Combine com <code>chromadb</code> para banco de
vetores.</li>
</ul></li>
<li><strong>LocalAI (API compat√≠vel com OpenAI)</strong>:
<ul>
<li><p>Instale:
<code>docker run -p 8080:8080 --name local-ai -ti localai/localai</code></p></li>
<li><p>Baixe modelo: Via web UI.</p></li>
<li><p>Python: Use OpenAI SDK apontando para
<code>http://localhost:8080/v1</code>.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> openai <span class="im">import</span> OpenAI</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>client <span class="op">=</span> OpenAI(base_url<span class="op">=</span><span class="st">&quot;http://localhost:8080/v1&quot;</span>, api_key<span class="op">=</span><span class="st">&quot;dummy&quot;</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Resto igual ao OpenAI</span></span></code></pre></div></li>
</ul></li>
<li><strong>OpenLLM (Da BentoML)</strong>:
<ul>
<li><code>pip install openllm</code></li>
<li>Rode: <code>openllm serve deepseek-coder:7b --port 3000</code></li>
<li>Acesse via OpenAI SDK em <code>http://localhost:3000</code>.</li>
</ul></li>
</ul>
<h3 data-number="1.2.7" id="dicas-para-aplica√ß√£o-de-pesquisa-inteligente"><span class="header-section-number">1.2.7</span> Dicas para Aplica√ß√£o de
Pesquisa Inteligente</h3>
<ul>
<li><strong>Framework</strong>: Use <code>langchain</code> ou
<code>llama-index</code> (<code>pip install langchain</code>) para
integrar LLM + busca (ex: web scraping com <code>beautifulsoup</code> +
embeddings).</li>
<li><strong>Exemplo simples de app</strong>: Crie um script que pesquisa
via Google Custom Search (free tier) e resume com DeepSeek.</li>
<li><strong>Limites e custos</strong>: Tiers free t√™m quotas (ex: 10k
tokens/dia). Para produ√ß√£o, migre para paid ou local.</li>
<li><strong>Recursos extras</strong>: Consulte <a href="https://huggingface.co/models">Hugging Face Models</a> para mais
LLMs free, ou <a href="https://github.com/cheahjs/free-llm-api-resources">cheahjs/free-llm-api-resources</a>
para listas atualizadas.</li>
</ul>
<p>Se precisar de c√≥digo mais espec√≠fico ou ajuda com um modelo, me
diga!</p>
<hr />
<p><em>Conversa exportada do Grok</em> <em>Processado em: 24/11/2025
22:27</em></p>

        <script id="fixed-toc-script">
        document.addEventListener('DOMContentLoaded', function() {
            const toc = document.getElementById('TOC');
            if (toc) {
                const tocTitle = toc.querySelector('h2');
                if (tocTitle) {
                    const toggleBtn = document.createElement('button');
                    toggleBtn.innerHTML = '‚ò∞';
                    toggleBtn.className = 'toc-toggle-btn';
                    toggleBtn.title = 'Minimizar/Expandir TOC';
                    let isMinimized = false;
                    toggleBtn.addEventListener('click', function(e) {
                        e.stopPropagation();
                        isMinimized = !isMinimized;
                        if (isMinimized) {
                            toc.classList.add('toc-minimized');
                        } else {
                            toc.classList.remove('toc-minimized');
                        }
                    });
                    tocTitle.appendChild(toggleBtn);
                }
            }
            
            // SCROLLSPY
            const sections = document.querySelectorAll('h1, h2, h3, h4, h5');
            const tocLinks = document.querySelectorAll('#TOC a');
            const observer = new IntersectionObserver((entries) => {
                entries.forEach(entry => {
                    if (entry.isIntersecting) {
                        const id = entry.target.getAttribute('id');
                        tocLinks.forEach(link => {
                            link.classList.remove('active');
                            if (link.getAttribute('href') === '#' + id) {
                                link.classList.add('active');
                            }
                        });
                    }
                });
            }, { 
                rootMargin: '-20% 0px -60% 0px', 
                threshold: 0 
            });
            
            sections.forEach(section => {
                if (section.id) observer.observe(section);
            });
            
            // Scroll suave
            tocLinks.forEach(link => {
                link.addEventListener('click', (e) => {
                    e.preventDefault();
                    const targetId = link.getAttribute('href').substring(1);
                    const targetElement = document.getElementById(targetId);
                    if (targetElement) {
                        const offsetTop = targetElement.offsetTop - 80;
                        window.scrollTo({ top: offsetTop, behavior: 'smooth' });
                    }
                });
            });
            
            // BOT√ÉO VOLTAR AO TOPO
            const backToTopBtn = document.createElement('button');
            backToTopBtn.className = 'back-to-top-content';
            backToTopBtn.innerHTML = '‚Üë';
            backToTopBtn.title = 'Voltar ao Topo';
            document.body.appendChild(backToTopBtn);
            
            window.addEventListener('scroll', () => {
                if (window.pageYOffset > 300) {
                    backToTopBtn.classList.add('show');
                } else {
                    backToTopBtn.classList.remove('show');
                }
            });
            
            backToTopBtn.addEventListener('click', () => {
                window.scrollTo({ top: 0, behavior: 'smooth' });
            });
        });
        </script>
        
</body>
</html>
