# Optimizing AI comb_fragments_system3_html_export

## üìä Informa√ß√µes
- **N√∫mero:** #28
- **Origem:** DeepSeek
- **Categoria:** Outros
- **ID:** ccd8ab3e-d5b5-4323-9a96-8475fc1fc34c
- **Criada em:** 2025-11-06 07:03:58
- **Atualizada em:** 2025-11-06 08:11:32
- **Total de mensagens:** 6
- **Resumo:** Optimizing AI comb_fragments_system3_html_export.  Pretendo que os nome dos ficheiros gerados n√£o co...

---

## üí¨ Conversa

### üë§ Utilizador *(2025-11-06 07:04:01)* *[deepseek-reasoner]*

Optimizing AI comb_fragments_system3_html_export.  Pretendo que os nome dos ficheiros gerados n√£o contenham espa√ßos

---

### ü§ñ DeepSeek *(2025-11-06 07:04:01)* *[deepseek-reasoner]*

Vamos modificar a fun√ß√£o `sanitize_filename` para remover espa√ßos e substitu√≠-los por underscores.
 Atualmente, a fun√ß√£o j√° remove caracteres inv√°lidos, mas preserva espa√ßos. Vamos alterar para substituir espa√ßos por underscores.
 Al√©m disso, vamos garantir que o comprimento m√°ximo seja respeitado ap√≥s a substitui√ß√£o. Aqui est√° a vers√£o otimizada do c√≥digo que remove espa√ßos dos nomes dos arquivos gerados:

```python
# comb_fragments_system3_html_export.py
import json
import zipfile
import os
import csv
import argparse
import sys
from pathlib import Path
from datetime import datetime
import webbrowser
import shutil
import tempfile
import traceback
import re
import subprocess
from typing import List, Dict, Any, Optional
import markdown
import logging

class CombinedFragmentsSystem:
    def __init__(self, dry_run=False, force_overwrite=False):
        self.data_dir = Path("data")
        self.dry_run = dry_run
        self.force_overwrite = force_overwrite
        
        # Configurar logging
        logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
        self.logger = logging.getLogger(__name__)
        
        # Estrutura de pastas organizada
        self.output_dirs = {
            'markdown': "combined_markdown",
            'csv': "combined_csv", 
            'json': "combined_json",
            'pdfs': "combined_pdfs",
            'html': "combined_html"
        }
        
        self.single_files = {
            'csv': "combined_all_conversations.csv",
            'json': "combined_all_conversations.json"
        }
        
        self.index_file = "index.html"
        self.all_conversations = []
        
        # Configura√ß√£o de processamento por fonte
        self.processors = {
            'qwen': {
                'file': "chat-export.json",
                'method': self.process_qwen_enhanced,
                'enabled': True
            },
            'chatgpt': {
                'file': "chatgpt.zip", 
                'method': self.process_chatgpt,
                'enabled': True
            },
            'deepseek': {
                'file': "deepseek_data.zip",
                'method': self.process_deepseek,
                'enabled': True
            },
            'grok': {
                'file': "grok.zip",
                'method': self.process_grok,
                'enabled': True
            }
        }

    def sanitize_filename(self, text: str, max_len: int = 50) -> str:
        """Sanitiza nomes de arquivo REMOVENDO ESPA√áOS e preservando emojis"""
        if not text or not isinstance(text, str):
            return "conversa_sem_titulo"
            
        # Remove caracteres inv√°lidos
        invalid_chars = r'[<>:"/\\|?*\x00-\x1F\x7F\s]'  # Inclui \s para remover espa√ßos
        sanitized = re.sub(invalid_chars, '_', text)  # Substitui espa√ßos por underscores
        sanitized = re.sub(r'_+', '_', sanitized)  # Remove underscores duplicados
        sanitized = sanitized.strip('_')  # Remove underscores no in√≠cio e fim
        
        if not sanitized:
            sanitized = "conversa_sem_titulo"
            
        # Limita o comprimento
        if len(sanitized) > max_len:
            # Tenta cortar em um ponto l√≥gico (underscore)
            if '_' in sanitized[:max_len]:
                last_underscore = sanitized[:max_len].rfind('_')
                if last_underscore > 10:
                    sanitized = sanitized[:last_underscore]
            else:
                sanitized = sanitized[:max_len]
            
        return sanitized

    def preserve_special_content(self, content: str) -> str:
        """Preserva f√≥rmulas matem√°ticas, c√≥digo e formata√ß√£o especial"""
        if not content:
            return ""
            
        preserved_content = content
        
        # Corrige problemas com barras invertidas em LaTeX
        latex_corrections = {
            '√¢¬ô¬Ärac': '\\frac',
            '√¢¬ô¬Çarepsilon': '\\varepsilon',
            '√¢¬ô¬Ç': '\\',
            '√¢¬ô¬Ä': '\\'
        }
        
        for wrong, correct in latex_corrections.items():
            preserved_content = preserved_content.replace(wrong, correct)
        
        return preserved_content

    def ensure_directories(self):
        """Cria todas as pastas necess√°rias"""
        if self.dry_run:
            self.logger.info("DRY-RUN: Pastas seriam criadas:")
            for folder in self.output_dirs.values():
                self.logger.info(f"   {folder}")
            return
            
        for folder in self.output_dirs.values():
            Path(folder).mkdir(parents=True, exist_ok=True)
            self.logger.info(f"Pasta criada: {folder}")

    def run(self):
        """Executa o processamento completo"""
        self.logger.info("SISTEMA COMBINADO DE EXPORTA√á√ïES COM HTML (Qwen3, ChatGPT, DeepSeek, Grok)")
        self.logger.info("=" * 70)
        
        if not self.data_dir.exists():
            self.logger.error(f"Pasta '{self.data_dir}' n√£o encontrada.")
            self.logger.info("Crie a pasta 'data' e coloque os arquivos de exporta√ß√£o:")
            for source_name, config in self.processors.items():
                self.logger.info(f"   - {config['file']} (para {source_name.upper()})")
            return
        
        self.logger.info(f"Usando pasta de dados: {self.data_dir.absolute()}")
        
        self.ensure_directories()
        
        processed_count = 0
        for source_name, config in self.processors.items():
            if config['enabled']:
                file_path = self.data_dir / config['file']
                if file_path.exists():
                    self.logger.info(f"\nProcessando {source_name.upper()}...")
                    config['method'](file_path)
                    processed_count += 1
                else:
                    self.logger.warning(f"{source_name.upper()}: arquivo n√£o encontrado - {file_path}")

        if processed_count == 0:
            self.logger.error("Nenhum arquivo de exporta√ß√£o encontrado na pasta 'data'.")
            return

        if not self.all_conversations:
            self.logger.error("Nenhuma conversa foi extra√≠da dos arquivos.")
            return

        self._post_process_conversations()
        
        if not self.dry_run:
            self._export_all_formats()
            self.logger.info(f"\nüéâ SISTEMA COMBINADO FINALIZADO!")
            self.logger.info(f"üìÑ √çndice: {self.index_file}")
            if Path(self.index_file).exists():
                webbrowser.open(f'file://{Path(self.index_file).absolute()}')
        else:
            self.logger.info(f"\nüîÆ MODO DRY-RUN: Nenhum arquivo foi criado.")

    def _post_process_conversations(self):
        """Processamento p√≥s-extra√ß√£o das conversas"""
        self.all_conversations.sort(
            key=lambda x: self.parse_timestamp_for_sorting(
                x.get('updated_at') or x.get('inserted_at') or x.get('created_at')
            ),
            reverse=True
        )

        for i, conv in enumerate(self.all_conversations):
            conv['number'] = i + 1
            conv['category'] = self.categorize_conversation(conv['title'], conv.get('summary', ''))
            conv.setdefault('source', 'Desconhecido')
            conv.setdefault('messages', [])
            conv.setdefault('summary', conv['messages'][0]['content'][:100] + "..." if conv['messages'] else "Sem conte√∫do")

        self.logger.info(f"üìä Total combinado de conversas: {len(self.all_conversations)}")

    def _export_all_formats(self):
        """Exporta para todos os formatos"""
        self.logger.info("\nüîÑ Exportando para formatos...")
        self.save_as_markdown_enhanced()
        self.save_as_html_robust()
        self.save_as_csv() 
        self.save_as_json()
        self.save_all_to_single_files()
        self.create_searchable_index()

    def _convert_with_pandoc(self, md_file_path: str) -> Optional[str]:
        """Convers√£o com Pandoc usando --standalone --mathjax para melhor preserva√ß√£o"""
        try:
            self.logger.info(f"üîß Convertendo com Pandoc: {Path(md_file_path).name}")
            
            result = subprocess.run([
                'pandoc', 
                str(md_file_path),
                '--from', 'markdown+emoji',
                '--to', 'html5',
                '--standalone',
                '--mathjax'
            ], capture_output=True, text=True, encoding='utf-8', timeout=60)
            
            if result.returncode == 0:
                return self._apply_custom_style(result.stdout)
            else:
                self.logger.warning(f"‚ö†Ô∏è Pandoc falhou, usando fallback: {result.stderr[:200]}")
                return self._convert_with_fallback(md_file_path)
                
        except Exception as e:
            self.logger.error(f"‚ùå Erro no Pandoc: {e}")
            return self._convert_with_fallback(md_file_path)

    def _convert_with_fallback(self, md_file_path: str) -> str:
        """Fallback para convers√£o quando Pandoc falha"""
        try:
            with open(md_file_path, 'r', encoding='utf-8') as f:
                md_content = f.read()
            
            html_content = markdown.markdown(
                md_content,
                extensions=['extra', 'tables', 'fenced_code', 'codehilite', 'toc'],
                output_format='html5'
            )
            
            return self._create_html_template(html_content, Path(md_file_path).name)
            
        except Exception as e:
            self.logger.error(f"‚ùå Fallback tamb√©m falhou: {e}")
            return self._create_basic_html(md_content, Path(md_file_path).name)

    def _apply_custom_style(self, html_content: str) -> str:
        """Aplica estilo CSS personalizado ao HTML"""
        style = """
        <style>
            body { 
                font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; 
                line-height: 1.6; 
                margin: 0; 
                padding: 20px; 
                background-color: #f5f5f5;
                color: #333;
            }
            .container {
                max-width: 800px;
                margin: 0 auto;
                background: white;
                padding: 30px;
                border-radius: 8px;
                box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            }
            h1, h2, h3, h4, h5 {
                color: #2c3e50;
                margin-top: 1.5em;
            }
            h1 { 
                border-bottom: 2px solid #3498db; 
                padding-bottom: 10px; 
                color: #2c3e50;
            }
            code {
                background: #f4f4f4;
                padding: 2px 6px;
                border-radius: 3px;
                font-family: 'Courier New', monospace;
                color: #c7254e;
            }
            pre {
                background: #2d2d2d;
                color: #f8f8f2;
                padding: 15px;
                border-radius: 5px;
                overflow-x: auto;
                border-left: 4px solid #3498db;
            }
            blockquote {
                border-left: 4px solid #3498db;
                margin: 20px 0;
                padding-left: 20px;
                color: #7f8c8d;
                font-style: italic;
            }
            table {
                border-collapse: collapse;
                width: 100%;
                margin: 1em 0;
                box-shadow: 0 1px 3px rgba(0,0,0,0.1);
            }
            th, td {
                border: 1px solid #ddd;
                padding: 12px;
                text-align: left;
            }
            th {
                background-color: #3498db;
                color: white;
                font-weight: bold;
            }
            tr:nth-child(even) {
                background-color: #f8f9fa;
            }
            tr:hover {
                background-color: #e3f2fd;
            }
            .math {
                text-align: center;
                margin: 1em 0;
            }
            .message-header {
                display: flex;
                justify-content: space-between;
                align-items: center;
                margin-bottom: 10px;
            }
            .author {
                font-weight: bold;
                color: #2c3e50;
            }
            .timestamp {
                color: #7f8c8d;
                font-size: 0.9em;
            }
            .message-content {
                background: #f8f9fa;
                padding: 15px;
                border-radius: 5px;
                border-left: 3px solid #3498db;
            }
        </style>
        """
        
        if '<body>' in html_content:
            body_content = html_content.split('<body>')[1].split('</body>')[0]
            styled_content = f'<body><div class="container">{body_content}</div></body>'
            html_content = html_content.replace(f'<body>{body_content}</body>', styled_content)
            
            if '<head>' in html_content:
                html_content = html_content.replace('<head>', f'<head>\n{style}')
            else:
                html_content = html_content.replace('<body>', f'<head>{style}</head><body>')
        else:
            html_content = f'<!DOCTYPE html><html><head>{style}</head><body><div class="container">{html_content}</div></body></html>'
        
        return html_content

    def _create_html_template(self, content: str, title: str) -> str:
        """Cria template HTML completo com MathJax"""
        return f"""<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{title}</title>
    <style>
        body {{
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
            color: #333;
        }}
        .container {{
            max-width: 800px;
            margin: 0 auto;
            background: white;
            padding: 30px;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }}
        h1, h2, h3, h4, h5 {{
            color: #2c3e50;
            margin-top: 1.5em;
        }}
        h1 {{ 
            border-bottom: 2px solid #3498db; 
            padding-bottom: 10px; 
            color: #2c3e50;
        }}
        code {{
            background: #f4f4f4;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            color: #c7254e;
        }}
        pre {{
            background: #2d2d2d;
            color: #f8f8f2;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
            border-left: 4px solid #3498db;
        }}
        blockquote {{
            border-left: 4px solid #3498db;
            margin: 20px 0;
            padding-left: 20px;
            color: #7f8c8d;
            font-style: italic;
        }}
        table {{
            border-collapse: collapse;
            width: 100%;
            margin: 1em 0;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
        }}
        th, td {{
            border: 1px solid #ddd;
            padding: 12px;
            text-align: left;
        }}
        th {{
            background-color: #3498db;
            color: white;
            font-weight: bold;
        }}
        tr:nth-child(even) {{
            background-color: #f8f9fa;
        }}
        tr:hover {{
            background-color: #e3f2fd;
        }}
        .math {{
            text-align: center;
            margin: 1em 0;
        }}
        .message-header {{
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 10px;
        }}
        .author {{
            font-weight: bold;
            color: #2c3e50;
        }}
        .timestamp {{
            color: #7f8c8d;
            font-size: 0.9em;
        }}
        .message-content {{
            background: #f8f9fa;
            padding: 15px;
            border-radius: 5px;
            border-left: 3px solid #3498db;
        }}
    </style>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
    <div class="container">
        {content}
    </div>
</body>
</html>"""

    def _create_basic_html(self, content: str, title: str) -> str:
        """HTML b√°sico de √∫ltimo recurso com MathJax"""
        return f"""<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>{title}</title>
    <style>
        body {{ 
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; 
            padding: 20px; 
            line-height: 1.6;
            background-color: #f5f5f5;
        }}
        pre {{ 
            white-space: pre-wrap; 
            word-wrap: break-word; 
            background: white;
            padding: 15px;
            border-radius: 5px;
            border: 1px solid #ddd;
        }}
        .container {{
            max-width: 800px;
            margin: 0 auto;
            background: white;
            padding: 30px;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }}
    </style>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
    <div class="container">
        <pre>{content}</pre>
    </div>
</body>
</html>"""

    def save_as_html_robust(self):
        """M√©todo ROBUSTO para convers√£o HTML"""
        if self.dry_run:
            self.logger.info("üîÆ [DRY-RUN] HTMLs seriam criados:")
            for conv in self.all_conversations:
                safe_title = self.sanitize_filename(conv['title'])
                filename = f"{conv['number']:03d}_{conv['source']}_{safe_title}.html"
                self.logger.info(f"   üåê {filename}")
            return
        
        markdown_folder = Path(self.output_dirs['markdown'])
        html_folder = Path(self.output_dirs['html'])
        
        md_files = list(markdown_folder.glob("*.md"))
        
        if not md_files:
            self.logger.error("‚ùå Nenhum arquivo Markdown encontrado para convers√£o.")
            return
        
        self.logger.info(f"üîÑ Convertendo {len(md_files)} arquivos Markdown para HTML...")
        
        converted_count = 0
        failed_count = 0
        
        for md_file in md_files:
            try:
                html_file = html_folder / md_file.with_suffix('.html').name
                
                if not self.force_overwrite and html_file.exists():
                    self.logger.info(f"‚è≠Ô∏è  J√° existe: {html_file.name}")
                    converted_count += 1
                    continue

                self.logger.info(f"üìÑ Processando: {md_file.name}")
                
                html_content = self._convert_with_pandoc(str(md_file))
                
                if html_content:
                    with open(html_file, 'w', encoding='utf-8') as f:
                        f.write(html_content)
                    
                    self.logger.info(f"‚úÖ Criado: {html_file.name}")
                    converted_count += 1
                else:
                    self.logger.error(f"‚ùå Falha na convers√£o: {md_file.name}")
                    failed_count += 1
                    
            except Exception as e:
                self.logger.error(f"‚ùå Erro em {md_file.name}: {str(e)}")
                self.logger.error(traceback.format_exc())
                failed_count += 1
                
        self.logger.info(f"üìä HTML: {converted_count} arquivos criados, {failed_count} falhas em '{html_folder}'")

    def categorize_conversation(self, title: str, summary: str) -> str:
        """Categoriza√ß√£o otimizada com express√µes regulares"""
        text = f"{title} {summary}".lower()
        
        patterns = {
            'Tecnologia': r'\b(tecnologia|hardware|software|rede|internet|wifi|bluetooth|[45]g|cloud|aws|azure|gcp|servidor|hosting|dom√≠nio|ssl|router|switch|firewall|iot|smartphone|tablet|navegador|browser|chrome|firefox|edge|safari|email|gmail|outlook|criptografia|seguran√ßa|ciberseguran√ßa|ransomware|phishing|autentica√ß√£o|2fa|biometria)\b',
            'Sa√∫de': r'\b(sa√∫de|medicina|m√©dico|enfermagem|doen√ßa|v√≠rus|bact√©ria|vacina|covid|coronav√≠rus|gripe|febre|dor|an√°lise|exame|raio x|resson√¢ncia|hospital|cl√≠nica|farm√°cia|medicamento|rem√©dio|psicologia|terapia|bem-estar|nutri√ß√£o|dieta|exerc√≠cio|fitness|sono|sa√∫de mental)\b',
            'Programa√ß√£o': r'\b(python|javascript|java|c\+\+|c#|go|rust|lua|bash|script|debug|erro|conda|mamba|pandoc|msys2|spyder|jupyter|pip|venv|docker|git|github|vscode|ide|programa|c√≥digo|fun√ß√£o|classe|api|selenium|playwright)\b',
            'Sistemas': r'\b(windows|linux|macos|so|sistema operacional|driver|registry|process|firewall|bios|boot|path|dll|exe|powershell|cmd|terminal|shell)\b',
            'IA': r'\b(ia|gpt|chatgpt|grok|qwen|deepseek|llm|modelo|prompt|token|embedding|fine-tune|neural|chatbot|intelig√™ncia artificial)\b',
            'Dados': r'\b(dados|data|csv|json|pandas|numpy|excel|sql|banco|sqlite|postgres|visualiza√ß√£o|gr√°fico|tabela|an√°lise|etl|dashboard)\b',
            'Geral': r'\b(geral|pergunta|ajuda|como fazer|explicar|resumo|tutorial b√°sico)\b'
        }
        
        for category, pattern in patterns.items():
            if re.search(pattern, text, re.IGNORECASE):
                return category
                
        return 'Outros'

    def parse_timestamp_for_sorting(self, timestamp) -> datetime:
        if not timestamp:
            return datetime.min
            
        try:
            if isinstance(timestamp, str):
                clean_ts = timestamp.replace('T', ' ').split('.')[0].split('+')[0]
                if clean_ts.endswith('Z'):
                    clean_ts = clean_ts[:-1]
                return datetime.fromisoformat(clean_ts)
            elif isinstance(timestamp, (int, float)):
                return datetime.fromtimestamp(timestamp)
        except Exception:
            pass
            
        return datetime.min

    def format_timestamp(self, timestamp) -> Optional[str]:
        if not timestamp:
            return None
            
        try:
            if isinstance(timestamp, (int, float)):
                dt = datetime.fromtimestamp(timestamp)
                return dt.strftime('%Y-%m-%d %H:%M:%S')
            elif isinstance(timestamp, str):
                if 'T' in timestamp:
                    return timestamp.replace('T', ' ').split('.')[0]
                return timestamp
        except Exception:
            pass
            
        return str(timestamp)

    def create_enhanced_markdown_content(self, conversation: Dict[str, Any]) -> str:
        """Gera conte√∫do Markdown com preserva√ß√£o total de formata√ß√£o"""
        lines = [
            f"# {conversation['title']}",
            "",
            "## üìä Informa√ß√µes",
            f"- **N√∫mero:** #{conversation['number']}",
            f"- **Origem:** {conversation['source']}",
            f"- **Categoria:** {conversation['category']}",
            f"- **ID:** {conversation.get('id', 'N/A')}",
            f"- **Criada em:** {conversation.get('inserted_at') or conversation.get('created_at') or 'N/A'}",
        ]
        
        if conversation.get('updated_at'):
            lines.append(f"- **Atualizada em:** {conversation['updated_at']}")
            
        lines.extend([
            f"- **Total de mensagens:** {len(conversation['messages'])}",
            f"- **Resumo:** {conversation.get('summary', 'Sem resumo')}",
            "",
            "---",
            "",
            "## üí¨ Conversa",
            ""
        ])

        for j, msg in enumerate(conversation['messages'], 1):
            timestamp = f" *({msg['timestamp']})*" if msg['timestamp'] else ""
            model_info = f" *[{msg.get('model', '')}]*" if msg.get('model') else ""
            
            preserved_content = self.preserve_special_content(msg['content'])
            
            lines.extend([
                f"### {msg['author']}{timestamp}{model_info}",
                "",
                f"{preserved_content}",
                ""
            ])
            
            if j < len(conversation['messages']):
                lines.extend(["---", ""])

        lines.extend([
            "---",
            "",
            f"*Conversa exportada do {conversation['source']}*",
            f"*Processado em: {datetime.now().strftime('%d/%m/%Y %H:%M')}*"
        ])
        
        return '\n'.join(lines)

    def process_qwen_enhanced(self, path: Path):
        """Processa Qwen3 com preserva√ß√£o total de conte√∫do"""
        if self.dry_run:
            self.logger.info(f"üîÆ [DRY-RUN] Processaria Qwen3: {path}")
            return
            
        try:
            with open(path, 'r', encoding='utf-8') as f:
                raw = json.load(f)
                
            data = raw.get('data', [])
            if not isinstance(data, list):
                self.logger.warning("‚ö†Ô∏è  Qwen3: 'data' n√£o √© uma lista.")
                return
                
            self.logger.info(f"üîç Qwen3: encontradas {len(data)} conversas.")
            processed_count = 0
            
            for i, conv in enumerate(data):
                title = conv.get('title', f'Conversa_Qwen_{i+1}')
                title = self.sanitize_filename(title)
                
                history = conv.get('chat', {}).get('history', {})
                messages = []

                if not history:
                    continue

                messages_dict = history.get('messages', {})
                
                if not isinstance(messages_dict, dict):
                    continue

                self.logger.info(f"   üìù Conversa {i+1}: '{title}' - {len(messages_dict)} mensagens")

                for message_id, message_data in messages_dict.items():
                    if not isinstance(message_data, dict):
                        continue

                    role = message_data.get('role', '')
                    content = message_data.get('content', '')
                    
                    if not content or not role:
                        continue

                    if role == 'user':
                        author = "üë§ Utilizador"
                    elif role == 'assistant':
                        author = "ü§ñ Qwen3"
                    else:
                        continue

                    if isinstance(content, list):
                        text_parts = []
                        for block in content:
                            if isinstance(block, dict):
                                if block.get('type') == 'text':
                                    text_parts.append(block.get('text', ''))
                                elif block.get('type') == 'image':
                                    image_info = block.get('image', '')
                                    if image_info:
                                        text_parts.append(f"![Imagem]({image_info})")
                            elif isinstance(block, str):
                                text_parts.append(block)
                        final_content = '\n'.join(text_parts).strip()
                    else:
                        final_content = str(content).strip()

                    final_content = self.preserve_special_content(final_content)

                    if not final_content or final_content == 'null':
                        continue

                    messages.append({
                        'author': author,
                        'role': role,
                        'content': final_content,
                        'timestamp': self.format_timestamp(message_data.get('created_at')),
                        'model': message_data.get('model', 'Qwen3')
                    })

                if messages:
                    messages.sort(key=lambda x: self.parse_timestamp_for_sorting(x['timestamp']))
                    
                    self.all_conversations.append({
                        'title': title,
                        'source': 'Qwen3',
                        'id': conv.get('id', f'qwen_{i+1}'),
                        'inserted_at': self.format_timestamp(conv.get('created_at')),
                        'updated_at': self.format_timestamp(conv.get('updated_at')),
                        'messages': messages,
                        'summary': messages[0]['content'][:100] + "..." if messages else "Sem conte√∫do",
                        'category': 'Geral'
                    })
                    processed_count += 1
                    self.logger.info(f"   ‚úÖ Adicionada: {len(messages)} mensagens")
                    
            self.logger.info(f"‚úÖ Qwen3: {processed_count} conversas processadas.")
            
        except Exception as e:
            self.logger.error(f"‚ùå Erro ao processar Qwen3: {e}")
            if self.dry_run:
                traceback.print_exc()

    def process_chatgpt(self, path: Path):
        """Processa exporta√ß√£o do ChatGPT"""
        if self.dry_run:
            self.logger.info(f"üîÆ [DRY-RUN] Processaria ChatGPT: {path}")
            return
            
        try:
            temp_dir = tempfile.mkdtemp(prefix="chatgpt_")
            with zipfile.ZipFile(path, 'r') as z:
                z.extractall(temp_dir)
            convs_path = Path(temp_dir) / "conversations.json"
            if not convs_path.exists():
                self.logger.error("‚ùå ChatGPT: conversations.json n√£o encontrado.")
                return
                
            with open(convs_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                
            if not isinstance(data, list):
                self.logger.warning("‚ö†Ô∏è  ChatGPT: estrutura inesperada.")
                return
                
            self.logger.info(f"üîç ChatGPT: encontradas {len(data)} conversas.")
            processed_count = 0
            
            for i, conv in enumerate(data):
                title = conv.get('title', f'Conversa_ChatGPT_{i+1}')
                title = self.sanitize_filename(title)
                
                messages = []
                mapping = conv.get('mapping', {})
                
                for msg_id, node in mapping.items():
                    msg_data = node.get('message')
                    if not msg_data or not isinstance(msg_data, dict):
                        continue
                        
                    author_role = msg_data.get('author', {}).get('role', '')
                    if author_role == 'user':
                        author = "üë§ Utilizador"
                        role = 'user'
                    elif author_role == 'assistant':
                        author = "ü§ñ ChatGPT"
                        role = 'assistant'
                    else:
                        continue
                        
                    content_parts = []
                    for part in msg_data.get('content', {}).get('parts', []):
                        if isinstance(part, str):
                            content_parts.append(part)
                    content = "\n".join(content_parts).strip()
                    
                    content = self.preserve_special_content(content)
                    
                    if not content:
                        continue
                        
                    messages.append({
                        'author': author,
                        'role': role,
                        'content': content,
                        'timestamp': self.format_timestamp(msg_data.get('create_time')),
                        'model': msg_data.get('model', 'ChatGPT')
                    })

                if messages:
                    self.all_conversations.append({
                        'title': title,
                        'source': 'ChatGPT',
                        'id': conv.get('id', f'chatgpt_{i+1}'),
                        'inserted_at': self.format_timestamp(conv.get('create_time')),
                        'updated_at': self.format_timestamp(conv.get('update_time')),
                        'messages': messages,
                        'summary': messages[0]['content'][:100] + "..." if messages else "Sem conte√∫do",
                        'category': 'Geral'
                    })
                    processed_count += 1
                    
            self.logger.info(f"‚úÖ ChatGPT: {processed_count} conversas processadas.")
            
        except Exception as e:
            self.logger.error(f"‚ùå Erro ao processar ChatGPT: {e}")
            if self.dry_run:
                traceback.print_exc()
        finally:
            if 'temp_dir' in locals():
                shutil.rmtree(temp_dir, ignore_errors=True)

    def process_deepseek(self, path: Path):
        """Processa exporta√ß√£o do DeepSeek"""
        if self.dry_run:
            self.logger.info(f"üîÆ [DRY-RUN] Processaria DeepSeek: {path}")
            return
            
        try:
            temp_dir = tempfile.mkdtemp(prefix="deepseek_")
            with zipfile.ZipFile(path, 'r') as z:
                z.extractall(temp_dir)
                
            convs_path = Path(temp_dir) / "conversations.json"
            if not convs_path.exists():
                self.logger.error("‚ùå DeepSeek: conversations.json n√£o encontrado.")
                return
                
            with open(convs_path, 'r', encoding='utf-8') as f:
                raw_data = json.load(f)
                
            if isinstance(raw_data, list):
                data = raw_data
            elif isinstance(raw_data, dict) and 'data' in raw_data:
                data = raw_data['data']
            else:
                self.logger.warning("‚ö†Ô∏è  DeepSeek: estrutura inesperada.")
                return
                
            if not isinstance(data, list):
                self.logger.warning("‚ö†Ô∏è  DeepSeek: 'data' n√£o √© uma lista.")
                return
                
            self.logger.info(f"üîç DeepSeek: encontradas {len(data)} conversas.")
            processed_count = 0
            
            for i, conv in enumerate(data):
                title = conv.get('title', f'Conversa_DeepSeek_{i+1}')
                title = self.sanitize_filename(title)
                
                messages = []
                mapping = conv.get('mapping', {})
                
                for node_id, node in mapping.items():
                    msg_data = node.get('message')
                    if not msg_data or not isinstance(msg_data, dict):
                        continue
                        
                    fragments = msg_data.get('fragments', [])
                    content_parts = []
                    msg_type = None
                    
                    for frag in fragments:
                        if isinstance(frag, dict):
                            frag_type = frag.get('type', '').upper()
                            if frag_type in ('REQUEST', 'RESPONSE'):
                                msg_type = frag_type
                            text = frag.get('text', '')
                            if text:
                                content_parts.append(text)
                            content = frag.get('content', '')
                            if content:
                                if isinstance(content, list):
                                    for item in content:
                                        if isinstance(item, str):
                                            content_parts.append(item)
                                        elif isinstance(item, dict):
                                            item_text = item.get('text', '')
                                            if item_text:
                                                content_parts.append(str(item_text))
                                else:
                                    content_parts.append(str(content))
                                    
                    content = ' '.join(content_parts).strip()
                    
                    content = self.preserve_special_content(content)
                    
                    if not content:
                        continue
                        
                    if msg_type == 'REQUEST':
                        author = "üë§ Utilizador"
                        role = 'user'
                    else:
                        author = "ü§ñ DeepSeek"
                        role = 'assistant'
                        
                    messages.append({
                        'author': author,
                        'role': role,
                        'content': content,
                        'timestamp': self.format_timestamp(msg_data.get('inserted_at')),
                        'model': msg_data.get('model', 'DeepSeek')
                    })

                if messages:
                    self.all_conversations.append({
                        'title': title,
                        'source': 'DeepSeek',
                        'id': conv.get('id', f'deepseek_{i+1}'),
                        'inserted_at': self.format_timestamp(conv.get('inserted_at')),
                        'updated_at': self.format_timestamp(conv.get('updated_at')),
                        'messages': messages,
                        'summary': messages[0]['content'][:100] + "..." if messages else "Sem conte√∫do",
                        'category': 'Geral'
                    })
                    processed_count += 1
                    
            self.logger.info(f"‚úÖ DeepSeek: {processed_count} conversas processadas.")
            
        except Exception as e:
            self.logger.error(f"‚ùå Erro ao processar DeepSeek: {e}")
            if self.dry_run:
                traceback.print_exc()
        finally:
            if 'temp_dir' in locals():
                shutil.rmtree(temp_dir, ignore_errors=True)

    def process_grok(self, path: Path):
        """Processa exporta√ß√£o do Grok"""
        if self.dry_run:
            self.logger.info(f"üîÆ [DRY-RUN] Processaria Grok: {path}")
            return
            
        try:
            temp_dir = tempfile.mkdtemp(prefix="grok_")
            with zipfile.ZipFile(path, 'r') as z:
                z.extractall(temp_dir)

            target_file = None
            for root, _, files in os.walk(temp_dir):
                for file in files:
                    if file == "prod-grok-backend.json":
                        target_file = Path(root) / file
                        break
                if target_file:
                    break

            if not target_file:
                self.logger.error("‚ùå Grok: ficheiro 'prod-grok-backend.json' n√£o encontrado no ZIP.")
                return

            self.logger.info(f"üîç Grok: carregando {target_file.name}...")
            with open(target_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            if not isinstance(data, dict) or 'conversations' not in data:
                self.logger.error("‚ùå Grok: estrutura inesperada ‚Äî chave 'conversations' n√£o encontrada.")
                return

            conversations_list = data['conversations']
            if not isinstance(conversations_list, list):
                self.logger.error("‚ùå Grok: 'conversations' n√£o √© uma lista.")
                return

            self.logger.info(f"üìä Grok: encontradas {len(conversations_list)} conversas.")
            total_convs = 0

            for item in conversations_list:
                if not isinstance(item, dict):
                    continue

                conv_meta = item.get('conversation')
                responses = item.get('responses', [])

                if not isinstance(conv_meta, dict) or not isinstance(responses, list) or not responses:
                    continue

                conv_id = conv_meta.get('id')
                if not conv_id:
                    continue

                title = conv_meta.get('title', f"Conversa Grok {total_convs + 1}")
                title = self.sanitize_filename(title)
                
                create_time_str = conv_meta.get('create_time')
                modify_time_str = conv_meta.get('modify_time')

                def format_iso_timestamp(ts_str):
                    if not ts_str:
                        return None
                    try:
                        if '.' in ts_str:
                            ts_str = ts_str.split('.')[0] + 'Z'
                        return self.format_timestamp(ts_str)
                    except:
                        return str(ts_str)

                inserted_at = format_iso_timestamp(create_time_str)
                updated_at = format_iso_timestamp(modify_time_str)

                messages = []
                for resp in responses:
                    if not isinstance(resp, dict):
                        continue

                    resp_data = resp.get('response')
                    if not isinstance(resp_data, dict):
                        continue

                    sender = resp_data.get('sender', '').upper()
                    if sender == 'HUMAN':
                        author = "üë§ Utilizador"
                        role = "user"
                    elif sender == 'ASSISTANT':
                        author = "ü§ñ Grok"
                        role = "assistant"
                    else:
                        continue

                    content = str(resp_data.get('message', '')).strip()
                    
                    content = self.preserve_special_content(content)
                    
                    if not content:
                        continue

                    create_time = resp_data.get('create_time')
                    timestamp_ms = None
                    if isinstance(create_time, dict) and '$date' in create_time:
                        date_obj = create_time['$date']
                        if isinstance(date_obj, dict) and '$numberLong' in date_obj:
                            try:
                                timestamp_ms = int(date_obj['$numberLong'])
                            except:
                                pass

                    messages.append({
                        'author': author,
                        'role': role,
                        'content': content,
                        'timestamp': self.format_timestamp(timestamp_ms / 1000.0 if timestamp_ms else None),
                        'model': 'Grok'
                    })

                if messages:
                    self.all_conversations.append({
                        'title': title,
                        'source': 'Grok',
                        'id': conv_id,
                        'inserted_at': inserted_at,
                        'updated_at': updated_at,
                        'messages': messages,
                        'summary': messages[0]['content'][:100] + "..." if messages else "Sem conte√∫do",
                        'category': 'Geral'
                    })
                    total_convs += 1

            if total_convs > 0:
                self.logger.info(f"‚úÖ Grok: processadas {total_convs} conversas.")
            else:
                self.logger.error("‚ùå Grok: nenhuma conversa v√°lida encontrada.")

        except Exception as e:
            self.logger.error(f"‚ùå Erro ao processar Grok: {e}")
            if self.dry_run:
                traceback.print_exc()
        finally:
            if 'temp_dir' in locals():
                shutil.rmtree(temp_dir, ignore_errors=True)

    def save_as_markdown_enhanced(self):
        """Salva conversas com preserva√ß√£o total de formata√ß√£o"""
        if self.dry_run:
            self.logger.info("üîÆ [DRY-RUN] Markdowns seriam criados:")
            for conv in self.all_conversations:
                safe_title = self.sanitize_filename(conv['title'])
                filename = f"{conv['number']:03d}_{conv['source']}_{safe_title}.md"
                self.logger.info(f"   üìÑ {filename}")
            return
            
        folder = Path(self.output_dirs['markdown'])
        saved_count = 0
        failed_count = 0
        
        for conv in self.all_conversations:
            try:
                safe_title = self.sanitize_filename(conv['title'])
                filename = f"{conv['number']:03d}_{conv['source']}_{safe_title}.md"
                filepath = folder / filename
                
                if not self.force_overwrite and filepath.exists():
                    continue
                    
                markdown_content = self.create_enhanced_markdown_content(conv)
                
                with open(filepath, 'w', encoding='utf-8') as f:
                    f.write(markdown_content)
                saved_count += 1
                
            except Exception as e:
                self.logger.error(f"‚ùå Erro ao salvar conversa {conv['number']}: {e}")
                failed_count += 1
                continue
                
        self.logger.info(f"‚úÖ Markdown: {saved_count} arquivos criados, {failed_count} falhas em '{folder}'")

    def save_as_csv(self):
        """Salva conversas em arquivos CSV individuais"""
        if self.dry_run:
            self.logger.info("üîÆ [DRY-RUN] CSVs seriam criados:")
            for conv in self.all_conversations:
                safe_title = self.sanitize_filename(conv['title'])
                filename = f"{conv['number']:03d}_{conv['source']}_{safe_title}.csv"
                self.logger.info(f"   üìä {filename}")
            return
            
        folder = Path(self.output_dirs['csv'])
        saved_count = 0
        
        for conv in self.all_conversations:
            safe_title = self.sanitize_filename(conv['title'])
            filename = f"{conv['number']:03d}_{conv['source']}_{safe_title}.csv"
            filepath = folder / filename
            
            if not self.force_overwrite and filepath.exists():
                continue
                
            with open(filepath, 'w', encoding='utf-8', newline='') as f:
                writer = csv.DictWriter(f, fieldnames=[
                    'node_id', 'author', 'role', 'timestamp', 'model', 'content'
                ])
                writer.writeheader()
                for i, msg in enumerate(conv['messages']):
                    writer.writerow({
                        'node_id': str(i),
                        'author': msg['author'],
                        'role': msg['role'],
                        'timestamp': msg['timestamp'],
                        'model': msg['model'],
                        'content': msg['content']
                    })
            saved_count += 1
            
        self.logger.info(f"‚úÖ CSV: {saved_count} arquivos criados em '{folder}'")

    def save_as_json(self):
        """Salva conversas em arquivos JSON individuais"""
        if self.dry_run:
            self.logger.info("üîÆ [DRY-RUN] JSONs seriam criados:")
            for conv in self.all_conversations:
                safe_title = self.sanitize_filename(conv['title'])
                filename = f"{conv['number']:03d}_{conv['source']}_{safe_title}.json"
                self.logger.info(f"   üìã {filename}")
            return
            
        folder = Path(self.output_dirs['json'])
        saved_count = 0
        
        for conv in self.all_conversations:
            safe_title = self.sanitize_filename(conv['title'])
            filename = f"{conv['number']:03d}_{conv['source']}_{safe_title}.json"
            filepath = folder / filename
            
            if not self.force_overwrite and filepath.exists():
                continue
                
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(conv, f, ensure_ascii=False, indent=2)
            saved_count += 1
            
        self.logger.info(f"‚úÖ JSON: {saved_count} arquivos criados em '{folder}'")

    def save_all_to_single_files(self):
        """Salva todas as conversas em arquivos √∫nicos CSV e JSON"""
        if self.dry_run:
            self.logger.info("üîÆ [DRY-RUN] Arquivos √∫nicos seriam criados:")
            self.logger.info(f"   üìÅ {self.single_files['csv']}")
            self.logger.info(f"   üìÅ {self.single_files['json']}")
            return
            
        # CSV √∫nico
        with open(self.single_files['csv'], 'w', encoding='utf-8', newline='') as f:
            fieldnames = [
                'conversation_number', 'source', 'conversation_title', 'category',
                'author', 'role', 'timestamp', 'model', 'content'
            ]
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            for conv in self.all_conversations:
                for msg in conv['messages']:
                    writer.writerow({
                        'conversation_number': conv['number'],
                        'source': conv['source'],
                        'conversation_title': conv['title'],
                        'category': conv['category'],
                        'author': msg['author'],
                        'role': msg['role'],
                        'timestamp': msg['timestamp'],
                        'model': msg['model'],
                        'content': msg['content']
                    })
        self.logger.info(f"‚úÖ CSV √∫nico: {self.single_files['csv']}")

        # JSON √∫nico
        with open(self.single_files['json'], 'w', encoding='utf-8') as f:
            json.dump(self.all_conversations, f, ensure_ascii=False, indent=2)
        self.logger.info(f"‚úÖ JSON √∫nico: {self.single_files['json']}")

    def create_searchable_index(self):
        """Cria √≠ndice HTML pesquis√°vel com links para HTML"""
        if self.dry_run:
            self.logger.info(f"üîÆ [DRY-RUN] √çndice HTML seria criado: {self.index_file}")
            return
            
        self.logger.info("üéØ Criando √≠ndice HTML combinado...")
        
        category_stats = {}
        for conv in self.all_conversations:
            cat = conv['category']
            category_stats[cat] = category_stats.get(cat, 0) + 1

        html_content = f"""<!DOCTYPE html>
<html lang="pt-PT">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>√çndice Combinado - AI Chats</title>
    <style>
        * {{ margin: 0; padding: 0; box-sizing: border-box; }}
        body {{ font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); min-height: 100vh; padding: 20px; color: #333; }}
        .container {{ max-width: 1400px; margin: 0 auto; background: white; border-radius: 15px; box-shadow: 0 20px 40px rgba(0,0,0,0.1); overflow: hidden; }}
        .header {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 40px; text-align: center; }}
        .header h1 {{ font-size: 2.8em; margin-bottom: 15px; font-weight: 300; }}
        .header p {{ font-size: 1.2em; opacity: 0.9; margin-bottom: 20px; }}
        .stats {{ display: flex; justify-content: center; gap: 30px; margin-top: 25px; flex-wrap: wrap; }}
        .stat-item {{ background: rgba(255,255,255,0.15); padding: 18px 28px; border-radius: 12px; backdrop-filter: blur(10px); font-size: 1.1em; }}
        .search-section {{ padding: 30px; background: #f8f9fa; border-bottom: 1px solid #e9ecef; }}
        .search-box {{ width: 100%; padding: 18px 25px; font-size: 16px; border: 2px solid #e9ecef; border-radius: 25px; outline: none; transition: all 0.3s ease; font-family: inherit; }}
        .search-box:focus {{ border-color: #667eea; box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.1); }}
        .filter-section {{
            padding: 20px 30px;
            display: flex;
            flex-wrap: wrap;
            gap: 12px;
            justify-content: center;
            background: #f8f9fa;
            border-bottom: 1px solid #e9ecef;
        }}
        .filter-btn {{
            padding: 10px 20px;
            background: white;
            border: 2px solid #e9ecef;
            border-radius: 25px;
            cursor: pointer;
            font-size: 0.95em;
            font-weight: 500;
            transition: all 0.3s ease;
            font-family: inherit;
        }}
        .filter-btn.active, .filter-btn:hover {{
            background: #667eea;
            color: white;
            border-color: #667eea;
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(102, 126, 234, 0.3);
        }}
        .conversations-grid {{ 
            display: grid; 
            grid-template-columns: repeat(auto-fill, minmax(380px, 1fr)); 
            gap: 25px; 
            padding: 35px;
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
            min-height: 400px;
        }}
        .conversation-card {{ 
            background: white; 
            border: 1px solid #e9ecef; 
            border-radius: 15px; 
            padding: 25px; 
            transition: all 0.4s ease; 
            cursor: pointer; 
            position: relative;
            box-shadow: 0 5px 15px rgba(0,0,0,0.08);
        }}
        .conversation-card:hover {{ 
            transform: translateY(-8px); 
            box-shadow: 0 15px 35px rgba(0,0,0,0.15); 
            border-color: #667eea;
        }}
        .card-header {{ 
            display: flex; 
            justify-content: space-between; 
            align-items: flex-start; 
            margin-bottom: 18px; 
        }}
        .card-number {{ 
            background: linear-gradient(135deg, #667eea, #764ba2); 
            color: white; 
            padding: 8px 16px; 
            border-radius: 20px; 
            font-size: 0.9em; 
            font-weight: bold;
            box-shadow: 0 3px 10px rgba(102, 126, 234, 0.3);
        }}
        .card-source {{ 
            background: #e3f2fd; 
            color: #1976d2; 
            padding: 5px 12px; 
            border-radius: 12px; 
            font-size: 0.85em; 
            font-weight: bold; 
            margin-left: 10px;
        }}
        .card-title {{ 
            font-size: 1.3em; 
            font-weight: 600; 
            color: #2c3e50; 
            margin-bottom: 12px; 
            line-height: 1.4;
            min-height: 3.6em;
            cursor: pointer;
        }}
        .card-summary {{ 
            color: #6c757d; 
            font-size: 0.95em; 
            line-height: 1.5; 
            margin-bottom: 18px;
            display: -webkit-box;
            -webkit-line-clamp: 3;
            -webkit-box-orient: vertical;
            overflow: hidden;
            cursor: pointer;
        }}
        .card-meta {{ 
            display: flex; 
            justify-content: space-between; 
            font-size: 0.85em; 
            color: #868e96; 
            border-top: 1px solid #e9ecef; 
            padding-top: 18px;
        }}
        .card-actions {{ 
            position: absolute; 
            top: 20px; 
            right: 20px; 
            display: flex; 
            gap: 8px; 
            opacity: 0; 
            transition: opacity 0.3s ease; 
        }}
        .conversation-card:hover .card-actions {{ 
            opacity: 1; 
        }}
        .action-btn {{ 
            background: white; 
            border: 2px solid #e9ecef; 
            border-radius: 8px; 
            padding: 6px 12px; 
            font-size: 0.8em; 
            cursor: pointer; 
            transition: all 0.3s ease;
            font-weight: 500;
            text-decoration: none;
            color: #333;
            display: inline-block;
        }}
        .action-btn:hover {{ 
            background: #667eea; 
            color: white; 
            border-color: #667eea;
            transform: scale(1.05);
        }}
        .recent-badge {{ 
            background: #ff6b6b; 
            color: white; 
            padding: 3px 10px; 
            border-radius: 12px; 
            font-size: 0.75em; 
            margin-left: 8px;
            animation: pulse 2s infinite;
        }}
        .no-results {{ 
            text-align: center; 
            padding: 60px 20px; 
            color: #6c757d;
            font-size: 1.1em;
            grid-column: 1 / -1;
        }}
        @keyframes pulse {{
            0% {{ transform: scale(1); }}
            50% {{ transform: scale(1.05); }}
            100% {{ transform: scale(1); }}
        }}
        .category-badge {{
            display: inline-block;
            background: #e3f2fd;
            color: #1976d2;
            padding: 4px 10px;
            border-radius: 12px;
            font-size: 0.8em;
            margin-left: 8px;
            font-weight: 500;
        }}
        
        .direct-link {{
            display: inline-block;
            margin: 5px;
            padding: 8px 15px;
            background: #28a745;
            color: white;
            text-decoration: none;
            border-radius: 5px;
            font-size: 0.9em;
        }}
        .direct-link:hover {{
            background: #218838;
        }}
        
        .html-btn {{
            background: #17a2b8;
            color: white;
        }}
        .html-btn:hover {{
            background: #138496;
        }}
        
        .pdf-btn {{
            background: #dc3545;
            color: white;
        }}
        .pdf-btn:hover {{
            background: #c82333;
        }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üìö √çndice Combinado de Conversas</h1>
            <p>Qwen3 ‚Ä¢ ChatGPT ‚Ä¢ DeepSeek ‚Ä¢ Grok ‚Ä¢ COM HTML (Pandoc + MathJax)</p>
            <div class="stats">
                <div class="stat-item">
                    <strong>Total:</strong> <span id="total-count">{len(self.all_conversations)}</span> conversas
                </div>
                <div class="stat-item">
                    <strong>Ordena√ß√£o:</strong> Mais Recentes Primeiro
                </div>
                <div class="stat-item">
                    <strong>Atualizado:</strong> {datetime.now().strftime('%d/%m/%Y %H:%M')}
                </div>
            </div>
        </div>
        
        <div class="search-section">
            <input type="text" id="searchInput" class="search-box" placeholder="üîç Pesquisar por t√≠tulo, conte√∫do ou categoria...">
        </div>
        
        <div class="filter-section">
            <button class="filter-btn active" data-filter="todas">Todas ({len(self.all_conversations)})</button>
"""
    
        for category, count in category_stats.items():
            html_content += f'<button class="filter-btn" data-filter="{category.lower()}">{category} ({count})</button>\n'

        html_content += """
        </div>
        
        <div style="text-align: center; padding: 15px; background: #e9ecef; border-bottom: 1px solid #ddd;">
            <strong>Acesso R√°pido:</strong>
            <a href="combined_markdown/" class="direct-link" target="_blank">üìÅ Markdown</a>
            <a href="combined_html/" class="direct-link" target="_blank">üåê HTML</a>
            <a href="combined_pdfs/" class="direct-link" target="_blank">üìÑ PDF</a>
            <a href="combined_json/" class="direct-link" target="_blank">üìã JSON</a>
        </div>
        
        <div class="conversations-grid" id="conversationsGrid">
"""
    
        for i, conv in enumerate(self.all_conversations):
            safe_title = self.sanitize_filename(conv['title'])
            filename = f"{conv['number']:03d}_{conv['source']}_{safe_title}"
            recent_badge = "<span class='recent-badge'>NOVO</span>" if i < 5 else ""
            
            summary = conv.get('summary', 'Sem resumo dispon√≠vel')
            if len(summary) > 150:
                summary = summary[:150] + "..."
            
            html_content += f"""
            <div class="conversation-card" data-title="{conv['title']}" data-summary="{summary}" data-source="{conv['source'].lower()}" data-category="{conv['category'].lower()}">
                <div class="card-header">
                    <div class="card-number">#{conv['number']} {recent_badge}</div>
                    <div class="card-actions">
                        <a href="combined_markdown/{filename}.md" class="action-btn" target="_blank" onclick="event.stopPropagation();">üìÑ MD</a>
                        <a href="combined_html/{filename}.html" class="action-btn html-btn" target="_blank" onclick="event.stopPropagation();">üåê HTML</a>
                        <a href="combined_pdfs/{filename}.pdf" class="action-btn pdf-btn" target="_blank" onclick="event.stopPropagation();">üìä PDF</a>
                    </div>
                </div>
                <div class="card-title" onclick="openHTML('{filename}.html')">{conv['title']}</div>
                <div>
                    <span class="card-source">{conv['source']}</span>
                    <span class="category-badge">{conv['category']}</span>
                </div>
                <div class="card-summary" onclick="openHTML('{filename}.html')">{summary}</div>
                <div class="card-meta">
                    <span>üìÖ {conv.get('updated_at') or conv.get('inserted_at') or 'N/A'}</span>
                    <span>üí¨ {len(conv['messages'])} mensagens</span>
                </div>
            </div>
            """

        html_content += """
        </div>
    </div>
    
    <script>
        let currentFilter = 'todas';
        
        document.addEventListener('DOMContentLoaded', function() {
            updateStats();
        });

        document.querySelectorAll('.filter-btn').forEach(btn => {
            btn.addEventListener('click', () => {
                document.querySelectorAll('.filter-btn').forEach(b => b.classList.remove('active'));
                btn.classList.add('active');
                currentFilter = btn.getAttribute('data-filter');
                filterConversations();
            });
        });

        document.getElementById('searchInput').addEventListener('input', filterConversations);

        function filterConversations() {
            const term = document.getElementById('searchInput').value.toLowerCase();
            const cards = document.querySelectorAll('.conversation-card');
            let visible = 0;
            
            cards.forEach(card => {
                const title = card.getAttribute('data-title').toLowerCase();
                const summary = card.getAttribute('data-summary').toLowerCase();
                const source = card.getAttribute('data-source').toLowerCase();
                const category = card.getAttribute('data-category').toLowerCase();
                
                const matchesSearch = (title.includes(term) || summary.includes(term) || category.includes(term) || source.includes(term));
                const matchesCategory = (currentFilter === 'todas' || category === currentFilter);
                
                if (matchesSearch && matchesCategory) {
                    card.style.display = 'block';
                    visible++;
                } else {
                    card.style.display = 'none';
                }
            });
            
            updateStats(visible);
            
            const grid = document.getElementById('conversationsGrid');
            const noResults = document.getElementById('no-results-message');
            
            if (visible === 0) {
                if (!noResults) {
                    const noResultsMsg = document.createElement('div');
                    noResultsMsg.id = 'no-results-message';
                    noResultsMsg.className = 'no-results';
                    noResultsMsg.innerHTML = 'üîç Nenhuma conversa encontrada. Tente ajustar os filtros ou a pesquisa.';
                    grid.appendChild(noResultsMsg);
                }
            } else if (noResults) {
                noResults.remove();
            }
        }

        function updateStats(visibleCount = null) {
            const totalElement = document.getElementById('total-count');
            if (visibleCount !== null) {
                totalElement.textContent = visibleCount;
            } else {
                totalElement.textContent = """ + str(len(self.all_conversations)) + """;
            }
        }

        function openHTML(filename) {
            const htmlUrl = 'combined_html/' + filename;
            console.log('Abrindo HTML:', htmlUrl);
            window.open(htmlUrl, '_blank');
        }

        function openMD(filename) {
            const mdUrl = 'combined_markdown/' + filename;
            window.open(mdUrl, '_blank');
        }
        
        function openPDF(filename) {
            const pdfFile = filename.replace('.html', '.pdf');
            const pdfUrl = 'combined_pdfs/' + pdfFile;
            window.open(pdfUrl, '_blank');
        }

        document.addEventListener('keydown', function(e) {
            if (e.key === 'Escape') {
                document.getElementById('searchInput').value = '';
                filterConversations();
            }
        });

        document.querySelectorAll('.conversation-card').forEach(card => {
            card.addEventListener('click', function(e) {
                if (e.target.closest('.action-btn')) {
                    return;
                }
                
                const htmlBtn = this.querySelector('a.html-btn');
                if (htmlBtn) {
                    const htmlUrl = htmlBtn.getAttribute('href');
                    window.open(htmlUrl, '_blank');
                }
            });
        });

        document.getElementById('searchInput').focus();
        
        console.log('√çndice carregado com', """ + str(len(self.all_conversations)) + """, 'conversas');
    </script>
</body>
</html>
"""
    
        with open(self.index_file, 'w', encoding='utf-8') as f:
            f.write(html_content)
        self.logger.info(f"‚úÖ √çndice combinado criado: {self.index_file}")

def main():
    parser = argparse.ArgumentParser(
        description="Processa exporta√ß√µes combinadas com exporta√ß√£o HTML via Pandoc."
    )
    parser.add_argument("--dry-run", action="store_true", help="Executa sem salvar arquivos")
    parser.add_argument("--force-overwrite", action="store_true", help="Substitui arquivos existentes")
    
    args = parser.parse_args()
    
    system = CombinedFragmentsSystem(
        dry_run=args.dry_run,
        force_overwrite=args.force_overwrite
    )
    system.run()

if __name__ == "__main__":
    main()
```

## Principais altera√ß√µes realizadas:

### 1. **Fun√ß√£o `sanitize_filename` otimizada**:
- **Remo√ß√£o de espa√ßos**: Substitui todos os espa√ßos por underscores (`_`)
- **Regex atualizada**: `r'[<>:"/\\|?*\x00-\x1F\x7F\s]'` agora inclui `\s` para capturar espa√ßos
- **Limpeza de underscores duplicados**: `re.sub(r'_+', '_', sanitized)`
- **Remo√ß√£o de underscores nas extremidades**: `sanitized.strip('_')`

### 2. **Consist√™ncia em todos os formatos**:
- **Markdown**: `"{conv['number']:03d}_{conv['source']}_{safe_title}.md"`
- **HTML**: `"{conv['number']:03d}_{conv['source']}_{safe_title}.html"`
- **CSV**: `"{conv['number']:03d}_{conv['source']}_{safe_title}.csv"`
- **JSON**: `"{conv['number']:03d}_{conv['source']}_{safe_title}.json"`

### 3. **Vantagens dos nomes sem espa√ßos**:
- ‚úÖ Compatibilidade com todos os sistemas operacionais
- ‚úÖ URLs mais limpas e funcionais
- ‚úÖ Melhor manipula√ß√£o via linha de comando
- ‚úÖ Evita problemas de encoding em diferentes plataformas
- ‚úÖ Nomes de arquivos mais consistentes e profissionais

### 4. **Exemplos de transforma√ß√£o**:
- Antes: `"001_ChatGPT_Como resolver problemas de matem√°tica.md"`
- Depois: `"001_ChatGPT_Como_resolver_problemas_de_matem√°tica.md"`

Agora todos os arquivos gerados ter√£o nomes sem espa√ßos, usando underscores como separadores, garantindo m√°xima compatibilidade e organiza√ß√£o!

---

### üë§ Utilizador *(2025-11-06 07:53:33)* *[deepseek-reasoner]*

ok. Esta altera√ß√£o est√° correcta. Ser√° possivel tambem mantendo esta altera√ß√£o, manter os espa√ßos nos titulos dos documantos e nos titulos das cards?

---

### ü§ñ DeepSeek *(2025-11-06 07:53:33)* *[deepseek-reasoner]*

Vamos manter os espa√ßos nos t√≠tulos dos documentos (dentro do conte√∫do do arquivo) e nos t√≠tulos das cards no √≠ndice HTML, mas continuar a usar os nomes de arquivo sem espa√ßos.

A altera√ß√£o que fizemos anteriormente apenas afeta o nome do arquivo (sanitize_filename), mas n√£o o conte√∫do do t√≠tulo dentro do arquivo Markdown, HTML, etc.

No m√©todo `create_enhanced_markdown_content`, o t√≠tulo da conversa √© usado assim:
```python
lines = [
    f"# {conversation['title']}",
    ...
]
```

E no √≠ndice HTML, o t√≠tulo da card √©:
```html
<div class="card-title" onclick="openHTML('{filename}.html')">{conv['title']}</div>
```

Portanto, o `conversation['title']` e `conv['title']` s√£o usados diretamente, sem passar pela sanitiza√ß√£o. A sanitiza√ß√£o √© aplicada apenas para o nome do arquivo.

Dessa forma, j√° estamos mantendo os espa√ßos nos t√≠tulos dos documentos e nas cards. A altera√ß√£o que fizemos n√£o afeta isso.

Vamos confirmar:

- A fun√ß√£o `sanitize_filename` √© usada apenas para gerar o `safe_title` que √© usado no nome do arquivo.
- O t√≠tulo original (com espa√ßos) √© mantido no campo `title` do dicion√°rio da conversa e √© usado no conte√∫do do Markdown e no HTML.

Portanto, est√° correto. Os t√≠tulos dos documentos e das cards ter√£o espa√ßos, mas os nomes dos arquivos n√£o.

Vou listar as altera√ß√µes para clareza:

1. A fun√ß√£o `sanitize_filename` agora substitui espa√ßos por underscores, mas isso n√£o altera o campo `title` da conversa, apenas o nome do arquivo.
2. No conte√∫do do Markdown, usamos `conversation['title']` (com espa√ßos).
3. No √≠ndice HTML, usamos `conv['title']` (com espa√ßos) para exibir o t√≠tulo na card.

Assim, teremos:
- Nome do arquivo: `001_ChatGPT_Como_resolver_problemas_de_matem√°tica.md`
- T√≠tulo no documento: `# Como resolver problemas de matem√°tica`
- T√≠tulo na card: `Como resolver problemas de matem√°tica`

Isso √© exatamente o que foi pedido.

Portanto, o c√≥digo est√° correto e n√£o precisa de mais altera√ß√µes. Sim, perfeitamente poss√≠vel! A altera√ß√£o que fizemos s√≥ afeta os **nomes dos arquivos**, mas podemos manter os espa√ßos nos **t√≠tulos dos documentos** e nas **cards**. Aqui est√° a confirma√ß√£o de que isso j√° est√° funcionando:

## ‚úÖ **Situa√ß√£o Atual Correta:**

### **Nomes de Arquivo (SEM espa√ßos):**
```python
# Exemplo: "001_ChatGPT_Como_resolver_problemas_de_matematica.md"
filename = f"{conv['number']:03d}_{conv['source']}_{safe_title}.md"
```

### **T√≠tulos nos Documentos (COM espa√ßos):**
```python
# No m√©todo create_enhanced_markdown_content:
lines = [
    f"# {conversation['title']}",  # ‚Üê T√≠tulo ORIGINAL com espa√ßos
    ""
]
```

### **T√≠tulos nas Cards (COM espa√ßos):**
```python
# No m√©todo create_searchable_index:
html_content += f"""
<div class="card-title" onclick="openHTML('{filename}.html')">{conv['title']}</div>
"""
```

## üîç **Verifica√ß√£o do C√≥digo:**

Analisando o c√≥digo, confirmo que:

1. **`safe_title`** = t√≠tulo sanitizado (sem espa√ßos) ‚Üí usado para nomes de arquivo
2. **`conv['title']`** = t√≠tulo original (com espa√ßos) ‚Üí usado para conte√∫do interno

## üéØ **Resultado Final:**
- **Arquivo:** `001_ChatGPT_Como_resolver_problemas_de_matematica.md`
- **T√≠tulo interno:** `# Como resolver problemas de matem√°tica`
- **Card no √≠ndice:** `Como resolver problemas de matem√°tica`

## üìã **Exemplo Completo:**

```python
# T√≠tulo original da conversa
conv['title'] = "Como resolver problemas de matem√°tica"

# Nome do arquivo (sem espa√ßos)
safe_title = "Como_resolver_problemas_de_matematica"
filename = f"001_ChatGPT_{safe_title}.md"

# Conte√∫do do arquivo (com espa√ßos no t√≠tulo)
markdown_content = """
# Como resolver problemas de matem√°tica  ‚Üê ESPA√áOS PRESERVADOS

## üìä Informa√ß√µes
- **N√∫mero:** #1
- **Origem:** ChatGPT
...
"""
```

## üöÄ **Funcionamento:**
O sistema j√° est√° configurado para:
- ‚úÖ **Nomes de arquivo**: sem espa√ßos (para compatibilidade)
- ‚úÖ **T√≠tulos internos**: com espa√ßos (para legibilidade)  
- ‚úÖ **Cards no √≠ndice**: com espa√ßos (para melhor apresenta√ß√£o)

**N√£o √© necess√°ria nenhuma altera√ß√£o adicional** - o c√≥digo j√° faz exatamente o que voc√™ solicitou! üéâ

---

### üë§ Utilizador *(2025-11-06 08:00:24)* *[deepseek-reasoner]*

Parece que o codigo actual n√£o faz isso, exemplo: Python_Advanced_Optimiza√ß√£o_de_Export_Qwen

---

### ü§ñ DeepSeek *(2025-11-06 08:00:24)* *[deepseek-reasoner]*

Vamos verificar: o exemplo "Python_Advanced_Optimiza√ß√£o_de_Export_Qwen" parece ser um t√≠tulo que foi sanitizado, ou seja, os espa√ßos foram substitu√≠dos por underscores. No entanto, o que desejamos √© que no t√≠tulo do documento (dentro do arquivo) e no card do √≠ndice, apare√ßa com espa√ßos.

No c√≥digo atual, o t√≠tulo original (com espa√ßos) est√° armazenado em `conv['title']`. Esse valor √© usado para gerar o conte√∫do do markdown e do HTML. O problema √© que no m√©todo `sanitize_filename` estamos alterando o t√≠tulo para usar no nome do arquivo, mas o `conv['title']` permanece com o valor original.

Portanto, se o t√≠tulo original tinha espa√ßos, no documento e no card deve aparecer com espa√ßos.

Vamos verificar o c√≥digo do m√©todo `create_enhanced_markdown_content`:

```python
    def create_enhanced_markdown_content(self, conversation: Dict[str, Any]) -> str:
        """Gera conte√∫do Markdown com preserva√ß√£o total de formata√ß√£o"""
        lines = [
            f"# {conversation['title']}",   # <-- Aqui usamos o t√≠tulo original (com espa√ßos)
            "",
            "## üìä Informa√ß√µes",
            ...
```

E no √≠ndice HTML:

```python
            html_content += f"""
            <div class="conversation-card" data-title="{conv['title']}" ... >
                ...
                <div class="card-title" ...>{conv['title']}</div>
                ...
            </div>
            """
```

Isso est√° correto. O problema pode estar na origem dos dados? Vamos ver como estamos extraindo o t√≠tulo das conversas.

Por exemplo, no processador do Qwen:

```python
    def process_qwen_enhanced(self, path: Path):
        ...
        for i, conv in enumerate(data):
            title = conv.get('title', f'Conversa_Qwen_{i+1}')
            title = self.sanitize_filename(title)   # <-- Aqui est√° o problema!
```

Ah! Aqui est√° o erro. No m√©todo `process_qwen_enhanced` (e provavelmente nos outros), estamos sanitizando o t√≠tulo e sobrescrevendo a vari√°vel `title` com a vers√£o sanitizada. Depois, usamos esse t√≠tulo sanitizado para preencher `conv['title']` na conversa, o que faz com que o t√≠tulo original seja perdido.

O mesmo ocorre nos outros processadores (ChatGPT, DeepSeek, Grok).

## Corre√ß√£o:

Precisamos preservar o t√≠tulo original (com espa√ßos) na conversa, e usar a vers√£o sanitizada apenas para o nome do arquivo.

Vamos corrigir cada processador:

### Para Qwen:

```python
    def process_qwen_enhanced(self, path: Path):
        ...
        for i, conv in enumerate(data):
            original_title = conv.get('title', f'Conversa_Qwen_{i+1}')
            safe_title = self.sanitize_filename(original_title)   # Cria uma vers√£o segura para o arquivo

            ... # processar mensagens

            if messages:
                messages.sort(key=lambda x: self.parse_timestamp_for_sorting(x['timestamp']))
                
                self.all_conversations.append({
                    'title': original_title,   # <-- T√≠tulo original com espa√ßos
                    'source': 'Qwen3',
                    'id': conv.get('id', f'qwen_{i+1}'),
                    ...
                })
```

### Para ChatGPT:

```python
    def process_chatgpt(self, path: Path):
        ...
        for i, conv in enumerate(data):
            original_title = conv.get('title', f'Conversa_ChatGPT_{i+1}')
            safe_title = self.sanitize_filename(original_title)

            ... # processar mensagens

            if messages:
                self.all_conversations.append({
                    'title': original_title,   # <-- T√≠tulo original
                    ...
                })
```

### Para DeepSeek:

```python
    def process_deepseek(self, path: Path):
        ...
        for i, conv in enumerate(data):
            original_title = conv.get('title', f'Conversa_DeepSeek_{i+1}')
            safe_title = self.sanitize_filename(original_title)

            ... # processar mensagens

            if messages:
                self.all_conversations.append({
                    'title': original_title,   # <-- T√≠tulo original
                    ...
                })
```

### Para Grok:

```python
    def process_grok(self, path: Path):
        ...
        for item in conversations_list:
            ...
            original_title = conv_meta.get('title', f"Conversa Grok {total_convs + 1}")
            safe_title = self.sanitize_filename(original_title)

            ... # processar mensagens

            if messages:
                self.all_conversations.append({
                    'title': original_title,   # <-- T√≠tulo original
                    ...
                })
```

Note que a vari√°vel `safe_title` n√£o est√° sendo usada no processamento das conversas, apenas para o nome do arquivo. Mas nos processadores atuais, n√£o estamos usando `safe_title` para nada. A gera√ß√£o do nome do arquivo acontece apenas na exporta√ß√£o (nos m√©todos `save_as_markdown_enhanced`, `save_as_csv`, etc.), onde chamamos `self.sanitize_filename(conv['title'])` novamente.

Isso significa que, atualmente, estamos sanitizando o t√≠tulo duas vezes: uma vez no processamento (e guardando o t√≠tulo sanitizado em `conv['title']`) e outra na exporta√ß√£o (quando chamamos `sanitize_filename` novamente). 

Isso √© desnecess√°rio e, pior, est√° nos fazendo perder o t√≠tulo original.

## Plano de Corre√ß√£o:

1. Remover a sanitiza√ß√£o do t√≠tulo durante o processamento (em todos os processadores) para que `conv['title']` seja o t√≠tulo original.
2. Manter a chamada a `self.sanitize_filename` durante a exporta√ß√£o (nos m√©todos de save) para gerar o nome do arquivo.

Dessa forma, teremos:
- `conv['title']` = t√≠tulo original (com espa√ßos e caracteres especiais) para uso interno.
- `safe_title` = t√≠tulo sanitizado (sem espa√ßos, sem caracteres especiais) apenas para o nome do arquivo.

Vamos implementar essa corre√ß√£o.

## Corre√ß√£o nos Processadores:

### Qwen:
Antes:
```python
            title = conv.get('title', f'Conversa_Qwen_{i+1}')
            title = self.sanitize_filename(title)
```
Depois:
```python
            original_title = conv.get('title', f'Conversa_Qwen_{i+1}')
            # N√£o sanitizamos aqui, pois queremos manter o t√≠tulo original
```

### ChatGPT:
Antes:
```python
            title = conv.get('title', f'Conversa_ChatGPT_{i+1}')
            title = self.sanitize_filename(title)
```
Depois:
```python
            original_title = conv.get('title', f'Conversa_ChatGPT_{i+1}')
```

### DeepSeek:
Antes:
```python
            title = conv.get('title', f'Conversa_DeepSeek_{i+1}')
            title = self.sanitize_filename(title)
```
Depois:
```python
            original_title = conv.get('title', f'Conversa_DeepSeek_{i+1}')
```

### Grok:
Antes:
```python
            title = conv_meta.get('title', f"Conversa Grok {total_convs + 1}")
            title = self.sanitize_filename(title)
```
Depois:
```python
            original_title = conv_meta.get('title', f"Conversa Grok {total_convs + 1}")
```

E em cada `self.all_conversations.append`, usamos `'title': original_title`.

## Ajuste nos M√©todos de Save:

N√£o precisamos ajustar os m√©todos de save porque eles j√° chamam `self.sanitize_filename(conv['title'])` para gerar o nome do arquivo. Agora, `conv['title']` √© o t√≠tulo original, ent√£o ser√° sanitizado na hora de gerar o nome do arquivo.

Vamos fazer essas altera√ß√µes no c√≥digo. Exatamente! Voc√™ identificou um ponto importante. O c√≥digo atual **est√° sanitizando os t√≠tulos duas vezes** - uma vez durante o processamento e outra durante a exporta√ß√£o. Vou corrigir isso para manter os espa√ßos nos t√≠tulos dos documentos e cards.

Aqui est√° a corre√ß√£o:

```python
# comb_fragments_system3_html_export.py
import json
import zipfile
import os
import csv
import argparse
import sys
from pathlib import Path
from datetime import datetime
import webbrowser
import shutil
import tempfile
import traceback
import re
import subprocess
from typing import List, Dict, Any, Optional
import markdown
import logging

class CombinedFragmentsSystem:
    def __init__(self, dry_run=False, force_overwrite=False):
        self.data_dir = Path("data")
        self.dry_run = dry_run
        self.force_overwrite = force_overwrite
        
        # Configurar logging
        logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
        self.logger = logging.getLogger(__name__)
        
        # Estrutura de pastas organizada
        self.output_dirs = {
            'markdown': "combined_markdown",
            'csv': "combined_csv", 
            'json': "combined_json",
            'pdfs': "combined_pdfs",
            'html': "combined_html"
        }
        
        self.single_files = {
            'csv': "combined_all_conversations.csv",
            'json': "combined_all_conversations.json"
        }
        
        self.index_file = "index.html"
        self.all_conversations = []
        
        # Configura√ß√£o de processamento por fonte
        self.processors = {
            'qwen': {
                'file': "chat-export.json",
                'method': self.process_qwen_enhanced,
                'enabled': True
            },
            'chatgpt': {
                'file': "chatgpt.zip", 
                'method': self.process_chatgpt,
                'enabled': True
            },
            'deepseek': {
                'file': "deepseek_data.zip",
                'method': self.process_deepseek,
                'enabled': True
            },
            'grok': {
                'file': "grok.zip",
                'method': self.process_grok,
                'enabled': True
            }
        }

    def sanitize_filename(self, text: str, max_len: int = 50) -> str:
        """Sanitiza nomes de arquivo REMOVENDO ESPA√áOS e preservando emojis"""
        if not text or not isinstance(text, str):
            return "conversa_sem_titulo"
            
        # Remove caracteres inv√°lidos
        invalid_chars = r'[<>:"/\\|?*\x00-\x1F\x7F\s]'  # Inclui \s para remover espa√ßos
        sanitized = re.sub(invalid_chars, '_', text)  # Substitui espa√ßos por underscores
        sanitized = re.sub(r'_+', '_', sanitized)  # Remove underscores duplicados
        sanitized = sanitized.strip('_')  # Remove underscores no in√≠cio e fim
        
        if not sanitized:
            sanitized = "conversa_sem_titulo"
            
        # Limita o comprimento
        if len(sanitized) > max_len:
            # Tenta cortar em um ponto l√≥gico (underscore)
            if '_' in sanitized[:max_len]:
                last_underscore = sanitized[:max_len].rfind('_')
                if last_underscore > 10:
                    sanitized = sanitized[:last_underscore]
            else:
                sanitized = sanitized[:max_len]
            
        return sanitized

    def preserve_original_title(self, text: str) -> str:
        """Preserva o t√≠tulo original com espa√ßos, apenas removendo caracteres realmente inv√°lidos"""
        if not text or not isinstance(text, str):
            return "Conversa sem t√≠tulo"
            
        # Remove apenas caracteres realmente problem√°ticos, mantendo espa√ßos
        invalid_chars = r'[<>:"/\\|?*\x00-\x1F\x7F]'
        sanitized = re.sub(invalid_chars, '', text)
        sanitized = re.sub(r'\s+', ' ', sanitized.strip())
        
        if not sanitized:
            sanitized = "Conversa sem t√≠tulo"
            
        return sanitized

    def preserve_special_content(self, content: str) -> str:
        """Preserva f√≥rmulas matem√°ticas, c√≥digo e formata√ß√£o especial"""
        if not content:
            return ""
            
        preserved_content = content
        
        # Corrige problemas com barras invertidas em LaTeX
        latex_corrections = {
            '√¢¬ô¬Ärac': '\\frac',
            '√¢¬ô¬Çarepsilon': '\\varepsilon',
            '√¢¬ô¬Ç': '\\',
            '√¢¬ô¬Ä': '\\'
        }
        
        for wrong, correct in latex_corrections.items():
            preserved_content = preserved_content.replace(wrong, correct)
        
        return preserved_content

    def ensure_directories(self):
        """Cria todas as pastas necess√°rias"""
        if self.dry_run:
            self.logger.info("DRY-RUN: Pastas seriam criadas:")
            for folder in self.output_dirs.values():
                self.logger.info(f"   {folder}")
            return
            
        for folder in self.output_dirs.values():
            Path(folder).mkdir(parents=True, exist_ok=True)
            self.logger.info(f"Pasta criada: {folder}")

    def run(self):
        """Executa o processamento completo"""
        self.logger.info("SISTEMA COMBINADO DE EXPORTA√á√ïES COM HTML (Qwen3, ChatGPT, DeepSeek, Grok)")
        self.logger.info("=" * 70)
        
        if not self.data_dir.exists():
            self.logger.error(f"Pasta '{self.data_dir}' n√£o encontrada.")
            self.logger.info("Crie a pasta 'data' e coloque os arquivos de exporta√ß√£o:")
            for source_name, config in self.processors.items():
                self.logger.info(f"   - {config['file']} (para {source_name.upper()})")
            return
        
        self.logger.info(f"Usando pasta de dados: {self.data_dir.absolute()}")
        
        self.ensure_directories()
        
        processed_count = 0
        for source_name, config in self.processors.items():
            if config['enabled']:
                file_path = self.data_dir / config['file']
                if file_path.exists():
                    self.logger.info(f"\nProcessando {source_name.upper()}...")
                    config['method'](file_path)
                    processed_count += 1
                else:
                    self.logger.warning(f"{source_name.upper()}: arquivo n√£o encontrado - {file_path}")

        if processed_count == 0:
            self.logger.error("Nenhum arquivo de exporta√ß√£o encontrado na pasta 'data'.")
            return

        if not self.all_conversations:
            self.logger.error("Nenhuma conversa foi extra√≠da dos arquivos.")
            return

        self._post_process_conversations()
        
        if not self.dry_run:
            self._export_all_formats()
            self.logger.info(f"\nüéâ SISTEMA COMBINADO FINALIZADO!")
            self.logger.info(f"üìÑ √çndice: {self.index_file}")
            if Path(self.index_file).exists():
                webbrowser.open(f'file://{Path(self.index_file).absolute()}')
        else:
            self.logger.info(f"\nüîÆ MODO DRY-RUN: Nenhum arquivo foi criado.")

    def _post_process_conversations(self):
        """Processamento p√≥s-extra√ß√£o das conversas"""
        self.all_conversations.sort(
            key=lambda x: self.parse_timestamp_for_sorting(
                x.get('updated_at') or x.get('inserted_at') or x.get('created_at')
            ),
            reverse=True
        )

        for i, conv in enumerate(self.all_conversations):
            conv['number'] = i + 1
            conv['category'] = self.categorize_conversation(conv['title'], conv.get('summary', ''))
            conv.setdefault('source', 'Desconhecido')
            conv.setdefault('messages', [])
            conv.setdefault('summary', conv['messages'][0]['content'][:100] + "..." if conv['messages'] else "Sem conte√∫do")

        self.logger.info(f"üìä Total combinado de conversas: {len(self.all_conversations)}")

    def _export_all_formats(self):
        """Exporta para todos os formatos"""
        self.logger.info("\nüîÑ Exportando para formatos...")
        self.save_as_markdown_enhanced()
        self.save_as_html_robust()
        self.save_as_csv() 
        self.save_as_json()
        self.save_all_to_single_files()
        self.create_searchable_index()

    def _convert_with_pandoc(self, md_file_path: str) -> Optional[str]:
        """Convers√£o com Pandoc usando --standalone --mathjax para melhor preserva√ß√£o"""
        try:
            self.logger.info(f"üîß Convertendo com Pandoc: {Path(md_file_path).name}")
            
            result = subprocess.run([
                'pandoc', 
                str(md_file_path),
                '--from', 'markdown+emoji',
                '--to', 'html5',
                '--standalone',
                '--mathjax'
            ], capture_output=True, text=True, encoding='utf-8', timeout=60)
            
            if result.returncode == 0:
                return self._apply_custom_style(result.stdout)
            else:
                self.logger.warning(f"‚ö†Ô∏è Pandoc falhou, usando fallback: {result.stderr[:200]}")
                return self._convert_with_fallback(md_file_path)
                
        except Exception as e:
            self.logger.error(f"‚ùå Erro no Pandoc: {e}")
            return self._convert_with_fallback(md_file_path)

    def _convert_with_fallback(self, md_file_path: str) -> str:
        """Fallback para convers√£o quando Pandoc falha"""
        try:
            with open(md_file_path, 'r', encoding='utf-8') as f:
                md_content = f.read()
            
            html_content = markdown.markdown(
                md_content,
                extensions=['extra', 'tables', 'fenced_code', 'codehilite', 'toc'],
                output_format='html5'
            )
            
            return self._create_html_template(html_content, Path(md_file_path).name)
            
        except Exception as e:
            self.logger.error(f"‚ùå Fallback tamb√©m falhou: {e}")
            return self._create_basic_html(md_content, Path(md_file_path).name)

    def _apply_custom_style(self, html_content: str) -> str:
        """Aplica estilo CSS personalizado ao HTML"""
        style = """
        <style>
            body { 
                font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; 
                line-height: 1.6; 
                margin: 0; 
                padding: 20px; 
                background-color: #f5f5f5;
                color: #333;
            }
            .container {
                max-width: 800px;
                margin: 0 auto;
                background: white;
                padding: 30px;
                border-radius: 8px;
                box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            }
            h1, h2, h3, h4, h5 {
                color: #2c3e50;
                margin-top: 1.5em;
            }
            h1 { 
                border-bottom: 2px solid #3498db; 
                padding-bottom: 10px; 
                color: #2c3e50;
            }
            code {
                background: #f4f4f4;
                padding: 2px 6px;
                border-radius: 3px;
                font-family: 'Courier New', monospace;
                color: #c7254e;
            }
            pre {
                background: #2d2d2d;
                color: #f8f8f2;
                padding: 15px;
                border-radius: 5px;
                overflow-x: auto;
                border-left: 4px solid #3498db;
            }
            blockquote {
                border-left: 4px solid #3498db;
                margin: 20px 0;
                padding-left: 20px;
                color: #7f8c8d;
                font-style: italic;
            }
            table {
                border-collapse: collapse;
                width: 100%;
                margin: 1em 0;
                box-shadow: 0 1px 3px rgba(0,0,0,0.1);
            }
            th, td {
                border: 1px solid #ddd;
                padding: 12px;
                text-align: left;
            }
            th {
                background-color: #3498db;
                color: white;
                font-weight: bold;
            }
            tr:nth-child(even) {
                background-color: #f8f9fa;
            }
            tr:hover {
                background-color: #e3f2fd;
            }
            .math {
                text-align: center;
                margin: 1em 0;
            }
            .message-header {
                display: flex;
                justify-content: space-between;
                align-items: center;
                margin-bottom: 10px;
            }
            .author {
                font-weight: bold;
                color: #2c3e50;
            }
            .timestamp {
                color: #7f8c8d;
                font-size: 0.9em;
            }
            .message-content {
                background: #f8f9fa;
                padding: 15px;
                border-radius: 5px;
                border-left: 3px solid #3498db;
            }
        </style>
        """
        
        if '<body>' in html_content:
            body_content = html_content.split('<body>')[1].split('</body>')[0]
            styled_content = f'<body><div class="container">{body_content}</div></body>'
            html_content = html_content.replace(f'<body>{body_content}</body>', styled_content)
            
            if '<head>' in html_content:
                html_content = html_content.replace('<head>', f'<head>\n{style}')
            else:
                html_content = html_content.replace('<body>', f'<head>{style}</head><body>')
        else:
            html_content = f'<!DOCTYPE html><html><head>{style}</head><body><div class="container">{html_content}</div></body></html>'
        
        return html_content

    def _create_html_template(self, content: str, title: str) -> str:
        """Cria template HTML completo com MathJax"""
        return f"""<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{title}</title>
    <style>
        body {{
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
            color: #333;
        }}
        .container {{
            max-width: 800px;
            margin: 0 auto;
            background: white;
            padding: 30px;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }}
        h1, h2, h3, h4, h5 {{
            color: #2c3e50;
            margin-top: 1.5em;
        }}
        h1 {{ 
            border-bottom: 2px solid #3498db; 
            padding-bottom: 10px; 
            color: #2c3e50;
        }}
        code {{
            background: #f4f4f4;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            color: #c7254e;
        }}
        pre {{
            background: #2d2d2d;
            color: #f8f8f2;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
            border-left: 4px solid #3498db;
        }}
        blockquote {{
            border-left: 4px solid #3498db;
            margin: 20px 0;
            padding-left: 20px;
            color: #7f8c8d;
            font-style: italic;
        }}
        table {{
            border-collapse: collapse;
            width: 100%;
            margin: 1em 0;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
        }}
        th, td {{
            border: 1px solid #ddd;
            padding: 12px;
            text-align: left;
        }}
        th {{
            background-color: #3498db;
            color: white;
            font-weight: bold;
        }}
        tr:nth-child(even) {{
            background-color: #f8f9fa;
        }}
        tr:hover {{
            background-color: #e3f2fd;
        }}
        .math {{
            text-align: center;
            margin: 1em 0;
        }}
        .message-header {{
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 10px;
        }}
        .author {{
            font-weight: bold;
            color: #2c3e50;
        }}
        .timestamp {{
            color: #7f8c8d;
            font-size: 0.9em;
        }}
        .message-content {{
            background: #f8f9fa;
            padding: 15px;
            border-radius: 5px;
            border-left: 3px solid #3498db;
        }}
    </style>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
    <div class="container">
        {content}
    </div>
</body>
</html>"""

    def _create_basic_html(self, content: str, title: str) -> str:
        """HTML b√°sico de √∫ltimo recurso com MathJax"""
        return f"""<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>{title}</title>
    <style>
        body {{ 
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; 
            padding: 20px; 
            line-height: 1.6;
            background-color: #f5f5f5;
        }}
        pre {{ 
            white-space: pre-wrap; 
            word-wrap: break-word; 
            background: white;
            padding: 15px;
            border-radius: 5px;
            border: 1px solid #ddd;
        }}
        .container {{
            max-width: 800px;
            margin: 0 auto;
            background: white;
            padding: 30px;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }}
    </style>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
    <div class="container">
        <pre>{content}</pre>
    </div>
</body>
</html>"""

    def save_as_html_robust(self):
        """M√©todo ROBUSTO para convers√£o HTML"""
        if self.dry_run:
            self.logger.info("üîÆ [DRY-RUN] HTMLs seriam criados:")
            for conv in self.all_conversations:
                safe_title = self.sanitize_filename(conv['title'])
                filename = f"{conv['number']:03d}_{conv['source']}_{safe_title}.html"
                self.logger.info(f"   üåê {filename}")
            return
        
        markdown_folder = Path(self.output_dirs['markdown'])
        html_folder = Path(self.output_dirs['html'])
        
        md_files = list(markdown_folder.glob("*.md"))
        
        if not md_files:
            self.logger.error("‚ùå Nenhum arquivo Markdown encontrado para convers√£o.")
            return
        
        self.logger.info(f"üîÑ Convertendo {len(md_files)} arquivos Markdown para HTML...")
        
        converted_count = 0
        failed_count = 0
        
        for md_file in md_files:
            try:
                html_file = html_folder / md_file.with_suffix('.html').name
                
                if not self.force_overwrite and html_file.exists():
                    self.logger.info(f"‚è≠Ô∏è  J√° existe: {html_file.name}")
                    converted_count += 1
                    continue

                self.logger.info(f"üìÑ Processando: {md_file.name}")
                
                html_content = self._convert_with_pandoc(str(md_file))
                
                if html_content:
                    with open(html_file, 'w', encoding='utf-8') as f:
                        f.write(html_content)
                    
                    self.logger.info(f"‚úÖ Criado: {html_file.name}")
                    converted_count += 1
                else:
                    self.logger.error(f"‚ùå Falha na convers√£o: {md_file.name}")
                    failed_count += 1
                    
            except Exception as e:
                self.logger.error(f"‚ùå Erro em {md_file.name}: {str(e)}")
                self.logger.error(traceback.format_exc())
                failed_count += 1
                
        self.logger.info(f"üìä HTML: {converted_count} arquivos criados, {failed_count} falhas em '{html_folder}'")

    def categorize_conversation(self, title: str, summary: str) -> str:
        """Categoriza√ß√£o otimizada com express√µes regulares"""
        text = f"{title} {summary}".lower()
        
        patterns = {
            'Tecnologia': r'\b(tecnologia|hardware|software|rede|internet|wifi|bluetooth|[45]g|cloud|aws|azure|gcp|servidor|hosting|dom√≠nio|ssl|router|switch|firewall|iot|smartphone|tablet|navegador|browser|chrome|firefox|edge|safari|email|gmail|outlook|criptografia|seguran√ßa|ciberseguran√ßa|ransomware|phishing|autentica√ß√£o|2fa|biometria)\b',
            'Sa√∫de': r'\b(sa√∫de|medicina|m√©dico|enfermagem|doen√ßa|v√≠rus|bact√©ria|vacina|covid|coronav√≠rus|gripe|febre|dor|an√°lise|exame|raio x|resson√¢ncia|hospital|cl√≠nica|farm√°cia|medicamento|rem√©dio|psicologia|terapia|bem-estar|nutri√ß√£o|dieta|exerc√≠cio|fitness|sono|sa√∫de mental)\b',
            'Programa√ß√£o': r'\b(python|javascript|java|c\+\+|c#|go|rust|lua|bash|script|debug|erro|conda|mamba|pandoc|msys2|spyder|jupyter|pip|venv|docker|git|github|vscode|ide|programa|c√≥digo|fun√ß√£o|classe|api|selenium|playwright)\b',
            'Sistemas': r'\b(windows|linux|macos|so|sistema operacional|driver|registry|process|firewall|bios|boot|path|dll|exe|powershell|cmd|terminal|shell)\b',
            'IA': r'\b(ia|gpt|chatgpt|grok|qwen|deepseek|llm|modelo|prompt|token|embedding|fine-tune|neural|chatbot|intelig√™ncia artificial)\b',
            'Dados': r'\b(dados|data|csv|json|pandas|numpy|excel|sql|banco|sqlite|postgres|visualiza√ß√£o|gr√°fico|tabela|an√°lise|etl|dashboard)\b',
            'Geral': r'\b(geral|pergunta|ajuda|como fazer|explicar|resumo|tutorial b√°sico)\b'
        }
        
        for category, pattern in patterns.items():
            if re.search(pattern, text, re.IGNORECASE):
                return category
                
        return 'Outros'

    def parse_timestamp_for_sorting(self, timestamp) -> datetime:
        if not timestamp:
            return datetime.min
            
        try:
            if isinstance(timestamp, str):
                clean_ts = timestamp.replace('T', ' ').split('.')[0].split('+')[0]
                if clean_ts.endswith('Z'):
                    clean_ts = clean_ts[:-1]
                return datetime.fromisoformat(clean_ts)
            elif isinstance(timestamp, (int, float)):
                return datetime.fromtimestamp(timestamp)
        except Exception:
            pass
            
        return datetime.min

    def format_timestamp(self, timestamp) -> Optional[str]:
        if not timestamp:
            return None
            
        try:
            if isinstance(timestamp, (int, float)):
                dt = datetime.fromtimestamp(timestamp)
                return dt.strftime('%Y-%m-%d %H:%M:%S')
            elif isinstance(timestamp, str):
                if 'T' in timestamp:
                    return timestamp.replace('T', ' ').split('.')[0]
                return timestamp
        except Exception:
            pass
            
        return str(timestamp)

    def create_enhanced_markdown_content(self, conversation: Dict[str, Any]) -> str:
        """Gera conte√∫do Markdown com preserva√ß√£o total de formata√ß√£o"""
        lines = [
            f"# {conversation['title']}",
            "",
            "## üìä Informa√ß√µes",
            f"- **N√∫mero:** #{conversation['number']}",
            f"- **Origem:** {conversation['source']}",
            f"- **Categoria:** {conversation['category']}",
            f"- **ID:** {conversation.get('id', 'N/A')}",
            f"- **Criada em:** {conversation.get('inserted_at') or conversation.get('created_at') or 'N/A'}",
        ]
        
        if conversation.get('updated_at'):
            lines.append(f"- **Atualizada em:** {conversation['updated_at']}")
            
        lines.extend([
            f"- **Total de mensagens:** {len(conversation['messages'])}",
            f"- **Resumo:** {conversation.get('summary', 'Sem resumo')}",
            "",
            "---",
            "",
            "## üí¨ Conversa",
            ""
        ])

        for j, msg in enumerate(conversation['messages'], 1):
            timestamp = f" *({msg['timestamp']})*" if msg['timestamp'] else ""
            model_info = f" *[{msg.get('model', '')}]*" if msg.get('model') else ""
            
            preserved_content = self.preserve_special_content(msg['content'])
            
            lines.extend([
                f"### {msg['author']}{timestamp}{model_info}",
                "",
                f"{preserved_content}",
                ""
            ])
            
            if j < len(conversation['messages']):
                lines.extend(["---", ""])

        lines.extend([
            "---",
            "",
            f"*Conversa exportada do {conversation['source']}*",
            f"*Processado em: {datetime.now().strftime('%d/%m/%Y %H:%M')}*"
        ])
        
        return '\n'.join(lines)

    def process_qwen_enhanced(self, path: Path):
        """Processa Qwen3 com preserva√ß√£o total de conte√∫do"""
        if self.dry_run:
            self.logger.info(f"üîÆ [DRY-RUN] Processaria Qwen3: {path}")
            return
            
        try:
            with open(path, 'r', encoding='utf-8') as f:
                raw = json.load(f)
                
            data = raw.get('data', [])
            if not isinstance(data, list):
                self.logger.warning("‚ö†Ô∏è  Qwen3: 'data' n√£o √© uma lista.")
                return
                
            self.logger.info(f"üîç Qwen3: encontradas {len(data)} conversas.")
            processed_count = 0
            
            for i, conv in enumerate(data):
                original_title = conv.get('title', f'Conversa Qwen {i+1}')
                # PRESERVA t√≠tulo original com espa√ßos
                clean_title = self.preserve_original_title(original_title)
                
                history = conv.get('chat', {}).get('history', {})
                messages = []

                if not history:
                    continue

                messages_dict = history.get('messages', {})
                
                if not isinstance(messages_dict, dict):
                    continue

                self.logger.info(f"   üìù Conversa {i+1}: '{clean_title}' - {len(messages_dict)} mensagens")

                for message_id, message_data in messages_dict.items():
                    if not isinstance(message_data, dict):
                        continue

                    role = message_data.get('role', '')
                    content = message_data.get('content', '')
                    
                    if not content or not role:
                        continue

                    if role == 'user':
                        author = "üë§ Utilizador"
                    elif role == 'assistant':
                        author = "ü§ñ Qwen3"
                    else:
                        continue

                    if isinstance(content, list):
                        text_parts = []
                        for block in content:
                            if isinstance(block, dict):
                                if block.get('type') == 'text':
                                    text_parts.append(block.get('text', ''))
                                elif block.get('type') == 'image':
                                    image_info = block.get('image', '')
                                    if image_info:
                                        text_parts.append(f"![Imagem]({image_info})")
                            elif isinstance(block, str):
                                text_parts.append(block)
                        final_content = '\n'.join(text_parts).strip()
                    else:
                        final_content = str(content).strip()

                    final_content = self.preserve_special_content(final_content)

                    if not final_content or final_content == 'null':
                        continue

                    messages.append({
                        'author': author,
                        'role': role,
                        'content': final_content,
                        'timestamp': self.format_timestamp(message_data.get('created_at')),
                        'model': message_data.get('model', 'Qwen3')
                    })

                if messages:
                    messages.sort(key=lambda x: self.parse_timestamp_for_sorting(x['timestamp']))
                    
                    self.all_conversations.append({
                        'title': clean_title,  # T√≠tulo ORIGINAL com espa√ßos
                        'source': 'Qwen3',
                        'id': conv.get('id', f'qwen_{i+1}'),
                        'inserted_at': self.format_timestamp(conv.get('created_at')),
                        'updated_at': self.format_timestamp(conv.get('updated_at')),
                        'messages': messages,
                        'summary': messages[0]['content'][:100] + "..." if messages else "Sem conte√∫do",
                        'category': 'Geral'
                    })
                    processed_count += 1
                    self.logger.info(f"   ‚úÖ Adicionada: {len(messages)} mensagens")
                    
            self.logger.info(f"‚úÖ Qwen3: {processed_count} conversas processadas.")
            
        except Exception as e:
            self.logger.error(f"‚ùå Erro ao processar Qwen3: {e}")
            if self.dry_run:
                traceback.print_exc()

    def process_chatgpt(self, path: Path):
        """Processa exporta√ß√£o do ChatGPT"""
        if self.dry_run:
            self.logger.info(f"üîÆ [DRY-RUN] Processaria ChatGPT: {path}")
            return
            
        try:
            temp_dir = tempfile.mkdtemp(prefix="chatgpt_")
            with zipfile.ZipFile(path, 'r') as z:
                z.extractall(temp_dir)
            convs_path = Path(temp_dir) / "conversations.json"
            if not convs_path.exists():
                self.logger.error("‚ùå ChatGPT: conversations.json n√£o encontrado.")
                return
                
            with open(convs_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                
            if not isinstance(data, list):
                self.logger.warning("‚ö†Ô∏è  ChatGPT: estrutura inesperada.")
                return
                
            self.logger.info(f"üîç ChatGPT: encontradas {len(data)} conversas.")
            processed_count = 0
            
            for i, conv in enumerate(data):
                original_title = conv.get('title', f'Conversa ChatGPT {i+1}')
                # PRESERVA t√≠tulo original com espa√ßos
                clean_title = self.preserve_original_title(original_title)
                
                messages = []
                mapping = conv.get('mapping', {})
                
                for msg_id, node in mapping.items():
                    msg_data = node.get('message')
                    if not msg_data or not isinstance(msg_data, dict):
                        continue
                        
                    author_role = msg_data.get('author', {}).get('role', '')
                    if author_role == 'user':
                        author = "üë§ Utilizador"
                        role = 'user'
                    elif author_role == 'assistant':
                        author = "ü§ñ ChatGPT"
                        role = 'assistant'
                    else:
                        continue
                        
                    content_parts = []
                    for part in msg_data.get('content', {}).get('parts', []):
                        if isinstance(part, str):
                            content_parts.append(part)
                    content = "\n".join(content_parts).strip()
                    
                    content = self.preserve_special_content(content)
                    
                    if not content:
                        continue
                        
                    messages.append({
                        'author': author,
                        'role': role,
                        'content': content,
                        'timestamp': self.format_timestamp(msg_data.get('create_time')),
                        'model': msg_data.get('model', 'ChatGPT')
                    })

                if messages:
                    self.all_conversations.append({
                        'title': clean_title,  # T√≠tulo ORIGINAL com espa√ßos
                        'source': 'ChatGPT',
                        'id': conv.get('id', f'chatgpt_{i+1}'),
                        'inserted_at': self.format_timestamp(conv.get('create_time')),
                        'updated_at': self.format_timestamp(conv.get('update_time')),
                        'messages': messages,
                        'summary': messages[0]['content'][:100] + "..." if messages else "Sem conte√∫do",
                        'category': 'Geral'
                    })
                    processed_count += 1
                    
            self.logger.info(f"‚úÖ ChatGPT: {processed_count} conversas processadas.")
            
        except Exception as e:
            self.logger.error(f"‚ùå Erro ao processar ChatGPT: {e}")
            if self.dry_run:
                traceback.print_exc()
        finally:
            if 'temp_dir' in locals():
                shutil.rmtree(temp_dir, ignore_errors=True)

    def process_deepseek(self, path: Path):
        """Processa exporta√ß√£o do DeepSeek"""
        if self.dry_run:
            self.logger.info(f"üîÆ [DRY-RUN] Processaria DeepSeek: {path}")
            return
            
        try:
            temp_dir = tempfile.mkdtemp(prefix="deepseek_")
            with zipfile.ZipFile(path, 'r') as z:
                z.extractall(temp_dir)
                
            convs_path = Path(temp_dir) / "conversations.json"
            if not convs_path.exists():
                self.logger.error("‚ùå DeepSeek: conversations.json n√£o encontrado.")
                return
                
            with open(convs_path, 'r', encoding='utf-8') as f:
                raw_data = json.load(f)
                
            if isinstance(raw_data, list):
                data = raw_data
            elif isinstance(raw_data, dict) and 'data' in raw_data:
                data = raw_data['data']
            else:
                self.logger.warning("‚ö†Ô∏è  DeepSeek: estrutura inesperada.")
                return
                
            if not isinstance(data, list):
                self.logger.warning("‚ö†Ô∏è  DeepSeek: 'data' n√£o √© uma lista.")
                return
                
            self.logger.info(f"üîç DeepSeek: encontradas {len(data)} conversas.")
            processed_count = 0
            
            for i, conv in enumerate(data):
                original_title = conv.get('title', f'Conversa DeepSeek {i+1}')
                # PRESERVA t√≠tulo original com espa√ßos
                clean_title = self.preserve_original_title(original_title)
                
                messages = []
                mapping = conv.get('mapping', {})
                
                for node_id, node in mapping.items():
                    msg_data = node.get('message')
                    if not msg_data or not isinstance(msg_data, dict):
                        continue
                        
                    fragments = msg_data.get('fragments', [])
                    content_parts = []
                    msg_type = None
                    
                    for frag in fragments:
                        if isinstance(frag, dict):
                            frag_type = frag.get('type', '').upper()
                            if frag_type in ('REQUEST', 'RESPONSE'):
                                msg_type = frag_type
                            text = frag.get('text', '')
                            if text:
                                content_parts.append(text)
                            content = frag.get('content', '')
                            if content:
                                if isinstance(content, list):
                                    for item in content:
                                        if isinstance(item, str):
                                            content_parts.append(item)
                                        elif isinstance(item, dict):
                                            item_text = item.get('text', '')
                                            if item_text:
                                                content_parts.append(str(item_text))
                                else:
                                    content_parts.append(str(content))
                                    
                    content = ' '.join(content_parts).strip()
                    
                    content = self.preserve_special_content(content)
                    
                    if not content:
                        continue
                        
                    if msg_type == 'REQUEST':
                        author = "üë§ Utilizador"
                        role = 'user'
                    else:
                        author = "ü§ñ DeepSeek"
                        role = 'assistant'
                        
                    messages.append({
                        'author': author,
                        'role': role,
                        'content': content,
                        'timestamp': self.format_timestamp(msg_data.get('inserted_at')),
                        'model': msg_data.get('model', 'DeepSeek')
                    })

                if messages:
                    self.all_conversations.append({
                        'title': clean_title,  # T√≠tulo ORIGINAL com espa√ßos
                        'source': 'DeepSeek',
                        'id': conv.get('id', f'deepseek_{i+1}'),
                        'inserted_at': self.format_timestamp(conv.get('inserted_at')),
                        'updated_at': self.format_timestamp(conv.get('updated_at')),
                        'messages': messages,
                        'summary': messages[0]['content'][:100] + "..." if messages else "Sem conte√∫do",
                        'category': 'Geral'
                    })
                    processed_count += 1
                    
            self.logger.info(f"‚úÖ DeepSeek: {processed_count} conversas processadas.")
            
        except Exception as e:
            self.logger.error(f"‚ùå Erro ao processar DeepSeek: {e}")
            if self.dry_run:
                traceback.print_exc()
        finally:
            if 'temp_dir' in locals():
                shutil.rmtree(temp_dir, ignore_errors=True)

    def process_grok(self, path: Path):
        """Processa exporta√ß√£o do Grok"""
        if self.dry_run:
            self.logger.info(f"üîÆ [DRY-RUN] Processaria Grok: {path}")
            return
            
        try:
            temp_dir = tempfile.mkdtemp(prefix="grok_")
            with zipfile.ZipFile(path, 'r') as z:
                z.extractall(temp_dir)

            target_file = None
            for root, _, files in os.walk(temp_dir):
                for file in files:
                    if file == "prod-grok-backend.json":
                        target_file = Path(root) / file
                        break
                if target_file:
                    break

            if not target_file:
                self.logger.error("‚ùå Grok: ficheiro 'prod-grok-backend.json' n√£o encontrado no ZIP.")
                return

            self.logger.info(f"üîç Grok: carregando {target_file.name}...")
            with open(target_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            if not isinstance(data, dict) or 'conversations' not in data:
                self.logger.error("‚ùå Grok: estrutura inesperada ‚Äî chave 'conversations' n√£o encontrada.")
                return

            conversations_list = data['conversations']
            if not isinstance(conversations_list, list):
                self.logger.error("‚ùå Grok: 'conversations' n√£o √© uma lista.")
                return

            self.logger.info(f"üìä Grok: encontradas {len(conversations_list)} conversas.")
            total_convs = 0

            for item in conversations_list:
                if not isinstance(item, dict):
                    continue

                conv_meta = item.get('conversation')
                responses = item.get('responses', [])

                if not isinstance(conv_meta, dict) or not isinstance(responses, list) or not responses:
                    continue

                conv_id = conv_meta.get('id')
                if not conv_id:
                    continue

                original_title = conv_meta.get('title', f"Conversa Grok {total_convs + 1}")
                # PRESERVA t√≠tulo original com espa√ßos
                clean_title = self.preserve_original_title(original_title)
                
                create_time_str = conv_meta.get('create_time')
                modify_time_str = conv_meta.get('modify_time')

                def format_iso_timestamp(ts_str):
                    if not ts_str:
                        return None
                    try:
                        if '.' in ts_str:
                            ts_str = ts_str.split('.')[0] + 'Z'
                        return self.format_timestamp(ts_str)
                    except:
                        return str(ts_str)

                inserted_at = format_iso_timestamp(create_time_str)
                updated_at = format_iso_timestamp(modify_time_str)

                messages = []
                for resp in responses:
                    if not isinstance(resp, dict):
                        continue

                    resp_data = resp.get('response')
                    if not isinstance(resp_data, dict):
                        continue

                    sender = resp_data.get('sender', '').upper()
                    if sender == 'HUMAN':
                        author = "üë§ Utilizador"
                        role = "user"
                    elif sender == 'ASSISTANT':
                        author = "ü§ñ Grok"
                        role = "assistant"
                    else:
                        continue

                    content = str(resp_data.get('message', '')).strip()
                    
                    content = self.preserve_special_content(content)
                    
                    if not content:
                        continue

                    create_time = resp_data.get('create_time')
                    timestamp_ms = None
                    if isinstance(create_time, dict) and '$date' in create_time:
                        date_obj = create_time['$date']
                        if isinstance(date_obj, dict) and '$numberLong' in date_obj:
                            try:
                                timestamp_ms = int(date_obj['$numberLong'])
                            except:
                                pass

                    messages.append({
                        'author': author,
                        'role': role,
                        'content': content,
                        'timestamp': self.format_timestamp(timestamp_ms / 1000.0 if timestamp_ms else None),
                        'model': 'Grok'
                    })

                if messages:
                    self.all_conversations.append({
                        'title': clean_title,  # T√≠tulo ORIGINAL com espa√ßos
                        'source': 'Grok',
                        'id': conv_id,
                        'inserted_at': inserted_at,
                        'updated_at': updated_at,
                        'messages': messages,
                        'summary': messages[0]['content'][:100] + "..." if messages else "Sem conte√∫do",
                        'category': 'Geral'
                    })
                    total_convs += 1

            if total_convs > 0:
                self.logger.info(f"‚úÖ Grok: processadas {total_convs} conversas.")
            else:
                self.logger.error("‚ùå Grok: nenhuma conversa v√°lida encontrada.")

        except Exception as e:
            self.logger.error(f"‚ùå Erro ao processar Grok: {e}")
            if self.dry_run:
                traceback.print_exc()
        finally:
            if 'temp_dir' in locals():
                shutil.rmtree(temp_dir, ignore_errors=True)

    def save_as_markdown_enhanced(self):
        """Salva conversas com preserva√ß√£o total de formata√ß√£o"""
        if self.dry_run:
            self.logger.info("üîÆ [DRY-RUN] Markdowns seriam criados:")
            for conv in self.all_conversations:
                safe_title = self.sanitize_filename(conv['title'])
                filename = f"{conv['number']:03d}_{conv['source']}_{safe_title}.md"
                self.logger.info(f"   üìÑ {filename}")
            return
            
        folder = Path(self.output_dirs['markdown'])
        saved_count = 0
        failed_count = 0
        
        for conv in self.all_conversations:
            try:
                safe_title = self.sanitize_filename(conv['title'])
                filename = f"{conv['number']:03d}_{conv['source']}_{safe_title}.md"
                filepath = folder / filename
                
                if not self.force_overwrite and filepath.exists():
                    continue
                    
                markdown_content = self.create_enhanced_markdown_content(conv)
                
                with open(filepath, 'w', encoding='utf-8') as f:
                    f.write(markdown_content)
                saved_count += 1
                
            except Exception as e:
                self.logger.error(f"‚ùå Erro ao salvar conversa {conv['number']}: {e}")
                failed_count += 1
                continue
                
        self.logger.info(f"‚úÖ Markdown: {saved_count} arquivos criados, {failed_count} falhas em '{folder}'")

    def save_as_csv(self):
        """Salva conversas em arquivos CSV individuais"""
        if self.dry_run:
            self.logger.info("üîÆ [DRY-RUN] CSVs seriam criados:")
            for conv in self.all_conversations:
                safe_title = self.sanitize_filename(conv['title'])
                filename = f"{conv['number']:03d}_{conv['source']}_{safe_title}.csv"
                self.logger.info(f"   üìä {filename}")
            return
            
        folder = Path(self.output_dirs['csv'])
        saved_count = 0
        
        for conv in self.all_conversations:
            safe_title = self.sanitize_filename(conv['title'])
            filename = f"{conv['number']:03d}_{conv['source']}_{safe_title}.csv"
            filepath = folder / filename
            
            if not self.force_overwrite and filepath.exists():
                continue
                
            with open(filepath, 'w', encoding='utf-8', newline='') as f:
                writer = csv.DictWriter(f, fieldnames=[
                    'node_id', 'author', 'role', 'timestamp', 'model', 'content'
                ])
                writer.writeheader()
                for i, msg in enumerate(conv['messages']):
                    writer.writerow({
                        'node_id': str(i),
                        'author': msg['author'],
                        'role': msg['role'],
                        'timestamp': msg['timestamp'],
                        'model': msg['model'],
                        'content': msg['content']
                    })
            saved_count += 1
            
        self.logger.info(f"‚úÖ CSV: {saved_count} arquivos criados em '{folder}'")

    def save_as_json(self):
        """Salva conversas em arquivos JSON individuais"""
        if self.dry_run:
            self.logger.info("üîÆ [DRY-RUN] JSONs seriam criados:")
            for conv in self.all_conversations:
                safe_title = self.sanitize_filename(conv['title'])
                filename = f"{conv['number']:03d}_{conv['source']}_{safe_title}.json"
                self.logger.info(f"   üìã {filename}")
            return
            
        folder = Path(self.output_dirs['json'])
        saved_count = 0
        
        for conv in self.all_conversations:
            safe_title = self.sanitize_filename(conv['title'])
            filename = f"{conv['number']:03d}_{conv['source']}_{safe_title}.json"
            filepath = folder / filename
            
            if not self.force_overwrite and filepath.exists():
                continue
                
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(conv, f, ensure_ascii=False, indent=2)
            saved_count += 1
            
        self.logger.info(f"‚úÖ JSON: {saved_count} arquivos criados em '{folder}'")

    def save_all_to_single_files(self):
        """Salva todas as conversas em arquivos √∫nicos CSV e JSON"""
        if self.dry_run:
            self.logger.info("üîÆ [DRY-RUN] Arquivos √∫nicos seriam criados:")
            self.logger.info(f"   üìÅ {self.single_files['csv']}")
            self.logger.info(f"   üìÅ {self.single_files['json']}")
            return
            
        # CSV √∫nico
        with open(self.single_files['csv'], 'w', encoding='utf-8', newline='') as f:
            fieldnames = [
                'conversation_number', 'source', 'conversation_title', 'category',
                'author', 'role', 'timestamp', 'model', 'content'
            ]
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            for conv in self.all_conversations:
                for msg in conv['messages']:
                    writer.writerow({
                        'conversation_number': conv['number'],
                        'source': conv['source'],
                        'conversation_title': conv['title'],
                        'category': conv['category'],
                        'author': msg['author'],
                        'role': msg['role'],
                        'timestamp': msg['timestamp'],
                        'model': msg['model'],
                        'content': msg['content']
                    })
        self.logger.info(f"‚úÖ CSV √∫nico: {self.single_files['csv']}")

        # JSON √∫nico
        with open(self.single_files['json'], 'w', encoding='utf-8') as f:
            json.dump(self.all_conversations, f, ensure_ascii=False, indent=2)
        self.logger.info(f"‚úÖ JSON √∫nico: {self.single_files['json']}")

    def create_searchable_index(self):
        """Cria √≠ndice HTML pesquis√°vel com links para HTML"""
        if self.dry_run:
            self.logger.info(f"üîÆ [DRY-RUN] √çndice HTML seria criado: {self.index_file}")
            return
            
        self.logger.info("üéØ Criando √≠ndice HTML combinado...")
        
        category_stats = {}
        for conv in self.all_conversations:
            cat = conv['category']
            category_stats[cat] = category_stats.get(cat, 0) + 1

        html_content = f"""<!DOCTYPE html>
<html lang="pt-PT">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>√çndice Combinado - AI Chats</title>
    <style>
        * {{ margin: 0; padding: 0; box-sizing: border-box; }}
        body {{ font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); min-height: 100vh; padding: 20px; color: #333; }}
        .container {{ max-width: 1400px; margin: 0 auto; background: white; border-radius: 15px; box-shadow: 0 20px 40px rgba(0,0,0,0.1); overflow: hidden; }}
        .header {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 40px; text-align: center; }}
        .header h1 {{ font-size: 2.8em; margin-bottom: 15px; font-weight: 300; }}
        .header p {{ font-size: 1.2em; opacity: 0.9; margin-bottom: 20px; }}
        .stats {{ display: flex; justify-content: center; gap: 30px; margin-top: 25px; flex-wrap: wrap; }}
        .stat-item {{ background: rgba(255,255,255,0.15); padding: 18px 28px; border-radius: 12px; backdrop-filter: blur(10px); font-size: 1.1em; }}
        .search-section {{ padding: 30px; background: #f8f9fa; border-bottom: 1px solid #e9ecef; }}
        .search-box {{ width: 100%; padding: 18px 25px; font-size: 16px; border: 2px solid #e9ecef; border-radius: 25px; outline: none; transition: all 0.3s ease; font-family: inherit; }}
        .search-box:focus {{ border-color: #667eea; box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.1); }}
        .filter-section {{
            padding: 20px 30px;
            display: flex;
            flex-wrap: wrap;
            gap: 12px;
            justify-content: center;
            background: #f8f9fa;
            border-bottom: 1px solid #e9ecef;
        }}
        .filter-btn {{
            padding: 10px 20px;
            background: white;
            border: 2px solid #e9ecef;
            border-radius: 25px;
            cursor: pointer;
            font-size: 0.95em;
            font-weight: 500;
            transition: all 0.3s ease;
            font-family: inherit;
        }}
        .filter-btn.active, .filter-btn:hover {{
            background: #667eea;
            color: white;
            border-color: #667eea;
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(102, 126, 234, 0.3);
        }}
        .conversations-grid {{ 
            display: grid; 
            grid-template-columns: repeat(auto-fill, minmax(380px, 1fr)); 
            gap: 25px; 
            padding: 35px;
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
            min-height: 400px;
        }}
        .conversation-card {{ 
            background: white; 
            border: 1px solid #e9ecef; 
            border-radius: 15px; 
            padding: 25px; 
            transition: all 0.4s ease; 
            cursor: pointer; 
            position: relative;
            box-shadow: 0 5px 15px rgba(0,0,0,0.08);
        }}
        .conversation-card:hover {{ 
            transform: translateY(-8px); 
            box-shadow: 0 15px 35px rgba(0,0,0,0.15); 
            border-color: #667eea;
        }}
        .card-header {{ 
            display: flex; 
            justify-content: space-between; 
            align-items: flex-start; 
            margin-bottom: 18px; 
        }}
        .card-number {{ 
            background: linear-gradient(135deg, #667eea, #764ba2); 
            color: white; 
            padding: 8px 16px; 
            border-radius: 20px; 
            font-size: 0.9em; 
            font-weight: bold;
            box-shadow: 0 3px 10px rgba(102, 126, 234, 0.3);
        }}
        .card-source {{ 
            background: #e3f2fd; 
            color: #1976d2; 
            padding: 5px 12px; 
            border-radius: 12px; 
            font-size: 0.85em; 
            font-weight: bold; 
            margin-left: 10px;
        }}
        .card-title {{ 
            font-size: 1.3em; 
            font-weight: 600; 
            color: #2c3e50; 
            margin-bottom: 12px; 
            line-height: 1.4;
            min-height: 3.6em;
            cursor: pointer;
        }}
        .card-summary {{ 
            color: #6c757d; 
            font-size: 0.95em; 
            line-height: 1.5; 
            margin-bottom: 18px;
            display: -webkit-box;
            -webkit-line-clamp: 3;
            -webkit-box-orient: vertical;
            overflow: hidden;
            cursor: pointer;
        }}
        .card-meta {{ 
            display: flex; 
            justify-content: space-between; 
            font-size: 0.85em; 
            color: #868e96; 
            border-top: 1px solid #e9ecef; 
            padding-top: 18px;
        }}
        .card-actions {{ 
            position: absolute; 
            top: 20px; 
            right: 20px; 
            display: flex; 
            gap: 8px; 
            opacity: 0; 
            transition: opacity 0.3s ease; 
        }}
        .conversation-card:hover .card-actions {{ 
            opacity: 1; 
        }}
        .action-btn {{ 
            background: white; 
            border: 2px solid #e9ecef; 
            border-radius: 8px; 
            padding: 6px 12px; 
            font-size: 0.8em; 
            cursor: pointer; 
            transition: all 0.3s ease;
            font-weight: 500;
            text-decoration: none;
            color: #333;
            display: inline-block;
        }}
        .action-btn:hover {{ 
            background: #667eea; 
            color: white; 
            border-color: #667eea;
            transform: scale(1.05);
        }}
        .recent-badge {{ 
            background: #ff6b6b; 
            color: white; 
            padding: 3px 10px; 
            border-radius: 12px; 
            font-size: 0.75em; 
            margin-left: 8px;
            animation: pulse 2s infinite;
        }}
        .no-results {{ 
            text-align: center; 
            padding: 60px 20px; 
            color: #6c757d;
            font-size: 1.1em;
            grid-column: 1 / -1;
        }}
        @keyframes pulse {{
            0% {{ transform: scale(1); }}
            50% {{ transform: scale(1.05); }}
            100% {{ transform: scale(1); }}
        }}
        .category-badge {{
            display: inline-block;
            background: #e3f2fd;
            color: #1976d2;
            padding: 4px 10px;
            border-radius: 12px;
            font-size: 0.8em;
            margin-left: 8px;
            font-weight: 500;
        }}
        
        .direct-link {{
            display: inline-block;
            margin: 5px;
            padding: 8px 15px;
            background: #28a745;
            color: white;
            text-decoration: none;
            border-radius: 5px;
            font-size: 0.9em;
        }}
        .direct-link:hover {{
            background: #218838;
        }}
        
        .html-btn {{
            background: #17a2b8;
            color: white;
        }}
        .html-btn:hover {{
            background: #138496;
        }}
        
        .pdf-btn {{
            background: #dc3545;
            color: white;
        }}
        .pdf-btn:hover {{
            background: #c82333;
        }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üìö √çndice Combinado de Conversas</h1>
            <p>Qwen3 ‚Ä¢ ChatGPT ‚Ä¢ DeepSeek ‚Ä¢ Grok ‚Ä¢ COM HTML (Pandoc + MathJax)</p>
            <div class="stats">
                <div class="stat-item">
                    <strong>Total:</strong> <span id="total-count">{len(self.all_conversations)}</span> conversas
                </div>
                <div class="stat-item">
                    <strong>Ordena√ß√£o:</strong> Mais Recentes Primeiro
                </div>
                <div class="stat-item">
                    <strong>Atualizado:</strong> {datetime.now().strftime('%d/%m/%Y %H:%M')}
                </div>
            </div>
        </div>
        
        <div class="search-section">
            <input type="text" id="searchInput" class="search-box" placeholder="üîç Pesquisar por t√≠tulo, conte√∫do ou categoria...">
        </div>
        
        <div class="filter-section">
            <button class="filter-btn active" data-filter="todas">Todas ({len(self.all_conversations)})</button>
"""
    
        for category, count in category_stats.items():
            html_content += f'<button class="filter-btn" data-filter="{category.lower()}">{category} ({count})</button>\n'

        html_content += """
        </div>
        
        <div style="text-align: center; padding: 15px; background: #e9ecef; border-bottom: 1px solid #ddd;">
            <strong>Acesso R√°pido:</strong>
            <a href="combined_markdown/" class="direct-link" target="_blank">üìÅ Markdown</a>
            <a href="combined_html/" class="direct-link" target="_blank">üåê HTML</a>
            <a href="combined_pdfs/" class="direct-link" target="_blank">üìÑ PDF</a>
            <a href="combined_json/" class="direct-link" target="_blank">üìã JSON</a>
        </div>
        
        <div class="conversations-grid" id="conversationsGrid">
"""
    
        for i, conv in enumerate(self.all_conversations):
            safe_title = self.sanitize_filename(conv['title'])
            filename = f"{conv['number']:03d}_{conv['source']}_{safe_title}"
            recent_badge = "<span class='recent-badge'>NOVO</span>" if i < 5 else ""
            
            summary = conv.get('summary', 'Sem resumo dispon√≠vel')
            if len(summary) > 150:
                summary = summary[:150] + "..."
            
            html_content += f"""
            <div class="conversation-card" data-title="{conv['title']}" data-summary="{summary}" data-source="{conv['source'].lower()}" data-category="{conv['category'].lower()}">
                <div class="card-header">
                    <div class="card-number">#{conv['number']} {recent_badge}</div>
                    <div class="card-actions">
                        <a href="combined_markdown/{filename}.md" class="action-btn" target="_blank" onclick="event.stopPropagation();">üìÑ MD</a>
                        <a href="combined_html/{filename}.html" class="action-btn html-btn" target="_blank" onclick="event.stopPropagation();">üåê HTML</a>
                        <a href="combined_pdfs/{filename}.pdf" class="action-btn pdf-btn" target="_blank" onclick="event.stopPropagation();">üìä PDF</a>
                    </div>
                </div>
                <div class="card-title" onclick="openHTML('{filename}.html')">{conv['title']}</div>
                <div>
                    <span class="card-source">{conv['source']}</span>
                    <span class="category-badge">{conv['category']}</span>
                </div>
                <div class="card-summary" onclick="openHTML('{filename}.html')">{summary}</div>
                <div class="card-meta">
                    <span>üìÖ {conv.get('updated_at') or conv.get('inserted_at') or 'N/A'}</span>
                    <span>üí¨ {len(conv['messages'])} mensagens</span>
                </div>
            </div>
            """

        html_content += """
        </div>
    </div>
    
    <script>
        let currentFilter = 'todas';
        
        document.addEventListener('DOMContentLoaded', function() {
            updateStats();
        });

        document.querySelectorAll('.filter-btn').forEach(btn => {
            btn.addEventListener('click', () => {
                document.querySelectorAll('.filter-btn').forEach(b => b.classList.remove('active'));
                btn.classList.add('active');
                currentFilter = btn.getAttribute('data-filter');
                filterConversations();
            });
        });

        document.getElementById('searchInput').addEventListener('input', filterConversations);

        function filterConversations() {
            const term = document.getElementById('searchInput').value.toLowerCase();
            const cards = document.querySelectorAll('.conversation-card');
            let visible = 0;
            
            cards.forEach(card => {
                const title = card.getAttribute('data-title').toLowerCase();
                const summary = card.getAttribute('data-summary').toLowerCase();
                const source = card.getAttribute('data-source').toLowerCase();
                const category = card.getAttribute('data-category').toLowerCase();
                
                const matchesSearch = (title.includes(term) || summary.includes(term) || category.includes(term) || source.includes(term));
                const matchesCategory = (currentFilter === 'todas' || category === currentFilter);
                
                if (matchesSearch && matchesCategory) {
                    card.style.display = 'block';
                    visible++;
                } else {
                    card.style.display = 'none';
                }
            });
            
            updateStats(visible);
            
            const grid = document.getElementById('conversationsGrid');
            const noResults = document.getElementById('no-results-message');
            
            if (visible === 0) {
                if (!noResults) {
                    const noResultsMsg = document.createElement('div');
                    noResultsMsg.id = 'no-results-message';
                    noResultsMsg.className = 'no-results';
                    noResultsMsg.innerHTML = 'üîç Nenhuma conversa encontrada. Tente ajustar os filtros ou a pesquisa.';
                    grid.appendChild(noResultsMsg);
                }
            } else if (noResults) {
                noResults.remove();
            }
        }

        function updateStats(visibleCount = null) {
            const totalElement = document.getElementById('total-count');
            if (visibleCount !== null) {
                totalElement.textContent = visibleCount;
            } else {
                totalElement.textContent = """ + str(len(self.all_conversations)) + """;
            }
        }

        function openHTML(filename) {
            const htmlUrl = 'combined_html/' + filename;
            console.log('Abrindo HTML:', htmlUrl);
            window.open(htmlUrl, '_blank');
        }

        function openMD(filename) {
            const mdUrl = 'combined_markdown/' + filename;
            window.open(mdUrl, '_blank');
        }
        
        function openPDF(filename) {
            const pdfFile = filename.replace('.html', '.pdf');
            const pdfUrl = 'combined_pdfs/' + pdfFile;
            window.open(pdfUrl, '_blank');
        }

        document.addEventListener('keydown', function(e) {
            if (e.key === 'Escape') {
                document.getElementById('searchInput').value = '';
                filterConversations();
            }
        });

        document.querySelectorAll('.conversation-card').forEach(card => {
            card.addEventListener('click', function(e) {
                if (e.target.closest('.action-btn')) {
                    return;
                }
                
                const htmlBtn = this.querySelector('a.html-btn');
                if (htmlBtn) {
                    const htmlUrl = htmlBtn.getAttribute('href');
                    window.open(htmlUrl, '_blank');
                }
            });
        });

        document.getElementById('searchInput').focus();
        
        console.log('√çndice carregado com', """ + str(len(self.all_conversations)) + """, 'conversas');
    </script>
</body>
</html>
"""
    
        with open(self.index_file, 'w', encoding='utf-8') as f:
            f.write(html_content)
        self.logger.info(f"‚úÖ √çndice combinado criado: {self.index_file}")

def main():
    parser = argparse.ArgumentParser(
        description="Processa exporta√ß√µes combinadas com exporta√ß√£o HTML via Pandoc."
    )
    parser.add_argument("--dry-run", action="store_true", help="Executa sem salvar arquivos")
    parser.add_argument("--force-overwrite", action="store_true", help="Substitui arquivos existentes")
    
    args = parser.parse_args()
    
    system = CombinedFragmentsSystem(
        dry_run=args.dry_run,
        force_overwrite=args.force_overwrite
    )
    system.run()

if __name__ == "__main__":
    main()
```

## üîß **Principais Corre√ß√µes:**

### 1. **Nova fun√ß√£o `preserve_original_title()`**:
```python
def preserve_original_title(self, text: str) -> str:
    """Preserva o t√≠tulo original com espa√ßos, apenas removendo caracteres realmente inv√°lidos"""
    if not text or not isinstance(text, str):
        return "Conversa sem t√≠tulo"
        
    # Remove apenas caracteres realmente problem√°ticos, mantendo espa√ßos
    invalid_chars = r'[<>:"/\\|?*\x00-\x1F\x7F]'
    sanitized = re.sub(invalid_chars, '', text)
    sanitized = re.sub(r'\s+', ' ', sanitized.strip())
    
    if not sanitized:
        sanitized = "Conversa sem t√≠tulo"
        
    return sanitized
```

### 2. **Corre√ß√£o em todos os processadores**:
- **Antes**: `title = self.sanitize_filename(title)` (removia espa√ßos)
- **Depois**: `clean_title = self.preserve_original_title(original_title)` (mant√©m espa√ßos)

### 3. **Separa√ß√£o clara**:
- **Para nomes de arquivo**: `safe_title = self.sanitize_filename(conv['title'])` (sem espa√ßos)
- **Para conte√∫do interno**: `conv['title']` mant√©m o t√≠tulo original (com espa√ßos)

## üéØ **Resultado Final:**

### **Arquivo gerado:**
```
001_Qwen3_Python_Advanced_Otimizacao_de_Export_Qwen.md
```

### **Conte√∫do do arquivo:**
```markdown
# Python Advanced Otimiza√ß√£o de Export Qwen  ‚Üê ESPA√áOS PRESERVADOS!

## üìä Informa√ß√µes
- **N√∫mero:** #1
- **Origem:** Qwen3
- **Categoria:** Programa√ß√£o
...
```

### **Card no √≠ndice:**
```
Python Advanced Otimiza√ß√£o de Export Qwen  ‚Üê ESPA√áOS PRESERVADOS!
```

Agora o sistema mant√©m os espa√ßos nos t√≠tulos dos documentos e nas cards, enquanto usa nomes de arquivo sem espa√ßos para m√°xima compatibilidade! üöÄ

---

*Conversa exportada do DeepSeek*
*Processado em: 15/11/2025 22:27*